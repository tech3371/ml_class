{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = ['age','workclass','fnlwgt','education','education_num','marital-status',\n",
    "               'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "               'hours-per-week','native-country']\n",
    "df = pd.read_csv('train-features.csv',names=columns_name,header=None,na_values=' ?')\n",
    "df['income'] = pd.read_csv('train-output.csv') #Binary (0 means <=50K, 1 means >50K)\n",
    "df.columns = df.columns.str.replace('-','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       "0          2174             0              40   United-States     0.0  \n",
       "1             0             0              13   United-States     0.0  \n",
       "2             0             0              40   United-States     0.0  \n",
       "3             0             0              40   United-States     0.0  \n",
       "4             0             0              40            Cuba     0.0  "
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.model = None\n",
    "        self.columns_name = ['age','workclass','fnlwgt','education','education_num',\n",
    "                                       'marital_status','occupation','relationship','race','sex',\n",
    "                                       'capital_gain','capital_loss','hours_per_week','native_country']\n",
    "        self.train_data = pd.read_csv('train-features.csv',names=self.columns_name,header=None,na_values=' ?')\n",
    "        self.train_label = pd.read_csv('train-output.csv',names=['income'],header=None) #Binary (0 means <=50K, 1 means >50K)\n",
    "#         self.train_label = self.train_label.values.ravel()\n",
    "        self.test_data = pd.read_csv('test-features.csv',names=self.columns_name,header=None,na_values=' ?')\n",
    "        \n",
    "        self.x_train = None\n",
    "        self.x_test  = None\n",
    "        self.y_train = None\n",
    "        self.y_test  = None\n",
    "    def preprocess(self,df,bins):\n",
    "        '''\n",
    "        Cleans df and performs feature engineering.\n",
    "        '''\n",
    "        # replace nan values with most commone values of it's column\n",
    "        for i in self.columns_name:\n",
    "            df[i] = df[i].fillna(list(dict(df_data['education'].dropna().value_counts()))[0])\n",
    "\n",
    "        # category\n",
    "        df['education'] = df['education'].str.replace('Preschool', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('10th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('11th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('12th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('1st-4th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('5th-6th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('7th-8th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('9th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('HS-Grad', 'HighGrad')\n",
    "        df['education'] = df['education'].str.replace('HS-grad', 'HighGrad')\n",
    "        df['education'] = df['education'].str.replace('Some-college', 'CommunityCollege')\n",
    "        df['education'] = df['education'].str.replace('Assoc-acdm', 'CommunityCollege')\n",
    "        df['education'] = df['education'].str.replace('Assoc-voc', 'CommunityCollege')\n",
    "        \n",
    "        # [' Never-married', ' Married-civ-spouse', ' Divorced',' Married-spouse-absent', ' Separated', ' Married-AF-spouse',\n",
    "        # ' Widowed']\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Never-married','notMarried')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Seperated','notMarried')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Divorced','Seperated')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Seperated','Seperated')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Married-AF-spouse','Married')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Married-civ-spouse','Married')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Married-spouse-absent','Married')\n",
    "        \n",
    "        # Binning\n",
    "        education_num = pd.cut(df.education_num,bins=[0,8,9,12,13,14,15,16],labels=[0,1,2,3,4,5,6])\n",
    "        df['education_num'] = education_num\n",
    "        \n",
    "        # Create categories for continuous values. Run it only once\n",
    "        age = pd.cut(df.age,bins)\n",
    "        hours = pd.cut(df.hours_per_week,bins=[0,20,40,100],labels=['PT','FT','OverTime'])\n",
    "        CG = pd.cut(df.capital_gain,bins)\n",
    "        CL = pd.cut(df.capital_loss,bins)\n",
    "        fnlwgt = pd.cut(df.fnlwgt,bins)\n",
    "        \n",
    "        # replace old column with new column with category values\n",
    "        df['age'] = age\n",
    "        df['hours_per_week'] = hours\n",
    "        df['capital_gain'] = CG\n",
    "        df['capital_loss'] = CL\n",
    "        df['fnlwgt'] = fnlwgt\n",
    "        \n",
    "        return df\n",
    "    def take_model(self,model):\n",
    "        '''\n",
    "        Takes in model.\n",
    "        '''\n",
    "        self.model = model\n",
    "        \n",
    "    def split_data(self,df_data,df_label):\n",
    "        \n",
    "        self.x_train,self.x_test, self.y_train, self.y_test = model_selection.train_test_split(df_data,df_label,test_size=0.2,random_state=2)\n",
    "\n",
    "        \n",
    "    def plain_training(self,df_data,df_label,test_df):\n",
    "        '''\n",
    "        It trains model once and returns accuracy score\n",
    "        '''\n",
    "        self.x_train,self.x_test, self.y_train, self.y_test = model_selection.train_test_split(df_data,df_label,test_size=0.2,random_state=2)\n",
    "        self.x_train = self.normalize_data(self.x_train)\n",
    "        self.x_test = self.normalize_data(self.x_test)\n",
    "        test = self.normalize_data(test_df)\n",
    "        clf = self.model()\n",
    "        clf.fit(self.x_train,self.y_train)\n",
    "        y_pred = clf.predict(test)\n",
    "        \n",
    "        return clf.score(self.x_test,self.y_test)\n",
    "    \n",
    "    def generate_submission(self, y_pred):\n",
    "        '''\n",
    "        Saves submission in the right format.\n",
    "        '''\n",
    "        pred_df = pd.DataFrame()\n",
    "        pred_df['Id'] = np.arange(0,len(y_pred))\n",
    "        pred_df['Category'] = y_pred\n",
    "        pred_df.to_csv('submission.csv',index=False)\n",
    "        \n",
    "    def encode_df(self,df):\n",
    "        '''\n",
    "        Encode string values in dataframe into numbers.\n",
    "        '''\n",
    "        \n",
    "        return df.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    def normalize_data(self, X):\n",
    "        # TO DO: Normalize the feature values of dataset X using the mean and standard deviation of the respective features \n",
    "#         min_max_scaler = preprocessing.MinMaxScaler() \n",
    "#         X = min_max_scaler.fit_transform(X)\n",
    "        \n",
    "        scaler = preprocessing.RobustScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        return X\n",
    "    \n",
    "    def kbins(self,df,bins):\n",
    "        from sklearn.preprocessing import KBinsDiscretizer\n",
    "        est = KBinsDiscretizer(n_bins=bins,encode='onehot-dense',strategy='kmeans')\n",
    "        est.fit(df)\n",
    "        Xt = est.transform(df)\n",
    "        \n",
    "        return Xt\n",
    "    def panda_onehotencode(self,train,test,selected):\n",
    "        '''\n",
    "        One hot encode train and test data. Then make sure they have same column amount.\n",
    "        # https://stackoverflow.com/questions/58101126/using-scikit-learn-onehotencoder-with-a-pandas-dataframe\n",
    "        https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
    "        \n",
    "        returns train, test\n",
    "        '''\n",
    "        tmp = pd.get_dummies(train[selected],prefix_sep='_',columns=selected)\n",
    "        print(\"train data shape: \",tmp.shape)\n",
    "\n",
    "        tmp1 = pd.get_dummies(test[selected],prefix_sep='_',columns=selected)\n",
    "        print(\"train data shape: \",tmp1.shape)\n",
    "\n",
    "#         for i in selected:\n",
    "#             tmp[i] = pd.get_dummies(train,prefix=[i], prefix_sep='_',columns = [i], drop_first=True)\n",
    "#         print(\"train data shape: \",tmp.shape)\n",
    "#         for i in selected:\n",
    "#             tmp1[i] = pd.get_dummies(test,prefix=[i], prefix_sep='_', columns = [i], drop_first=True)\n",
    "#         print(\"test data shape: \",tmp.shape)\n",
    "        final_train, final_test = tmp.align(tmp1, join='inner', axis=1)  # inner join\n",
    "        print(\"final train data : {}\\nfinal test data: {}\".format(final_train.shape,final_test.shape))\n",
    "        return final_train,final_test\n",
    "    \n",
    "    def category_labelencoder(self,data):\n",
    "        '''\n",
    "        convert categories into something.\n",
    "        https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
    "        \n",
    "        But I don't know how to make test and train with same column shape.\n",
    "        '''\n",
    "        tmp = data\n",
    "        # print(df_data.head() )\n",
    "        categorical_feature_mask = tmp.dtypes==object # gets features with string or object value\n",
    "        categorical_feature_mask\n",
    "        # filter categorical columns using mask and turn it into a list\n",
    "        categorical_cols = tmp.columns[categorical_feature_mask].tolist()\n",
    "        categorical_cols\n",
    "\n",
    "        # instantiate labelencoder object\n",
    "        le = LabelEncoder()\n",
    "        # apply le on categorical feature columns\n",
    "        tmp[categorical_cols] = tmp[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "        tmp[categorical_cols].head(10)\n",
    "\n",
    "        # instantiate OneHotEncoder\n",
    "        ohe = OneHotEncoder(categorical_features = categorical_feature_mask, sparse=False ) \n",
    "        # categorical_features = boolean mask for categorical columns\n",
    "        # sparse = False output an array not sparse matrix\n",
    "\n",
    "        # apply OneHotEncoder on categorical feature columns\n",
    "        test_ohe = ohe.fit_transform(tmp) # It returns an numpy array\n",
    "        return test_ohe\n",
    "    def kfold_cw(self,model,df_data,df_label,df_test,niter):\n",
    "        scores = cross_val_score(model,df_data,df_label,cv=niter)\n",
    "        print(\"Accuracy score: \",score)\n",
    "#         pred  = cross_val_predict(model,df_data,df_label,cv=niter)\n",
    "        print('fitting now')\n",
    "        final_model = model.fit(df_data,df_label)\n",
    "        print('final prediction')\n",
    "        new_pred = model.predict(df_test)\n",
    "        \n",
    "#         # manual k-fold implementation \n",
    "#         # https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833\n",
    "\n",
    "#         X = df_data.to_numpy() # feature with good correlation with class\n",
    "#         y = df_label.values.ravel()\n",
    "\n",
    "#         scores = []\n",
    "#         acc = []\n",
    "#         cv = KFold(n_splits=niter, random_state=42,shuffle=True)\n",
    "#         i = 0\n",
    "#         for train_index, test_index in cv.split(X):\n",
    "#             print(i)\n",
    "#             i +=1\n",
    "#             X_train, X_test, y_train, y_test = X[train_index], X[test_index,:], y[train_index], y[test_index]\n",
    "#             model.fit(X_train, y_train)\n",
    "#             scores.append(model.score(X_test, y_test))\n",
    "#             acc.append(accuracy_score(model.predict(X_test),y_test))\n",
    "#         model.fit(X,y)\n",
    "#         new_pred = model.predict(df_test)\n",
    "#         print(\"acc \", np.mean(acc))\n",
    "        return np.mean(scores),new_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'education_num', 'marital_status', 'relationship', 'sex', 'capital_gain']\n",
      "age [(38.9, 46.2], (46.2, 53.5], (31.6, 38.9], (24.3, 31.6], (16.927, 24.3], (53.5, 60.8], (75.4, 82.7], (60.8, 68.1], (68.1, 75.4], (82.7, 90.0]]\n",
      "Categories (10, interval[float64]): [(16.927, 24.3] < (24.3, 31.6] < (31.6, 38.9] < (38.9, 46.2] ... (60.8, 68.1] < (68.1, 75.4] < (75.4, 82.7] < (82.7, 90.0]]\n",
      "education_num [3, 1, 0, 4, 2, 6, 5]\n",
      "Categories (7, int64): [0 < 1 < 2 < 3 < 4 < 5 < 6]\n",
      "marital_status [' notMarried' ' Married' ' Seperated' ' Separated' ' Widowed']\n",
      "relationship [' Not-in-family' ' Husband' ' Wife' ' Own-child' ' Unmarried'\n",
      " ' Other-relative']\n",
      "sex [' Male' ' Female']\n",
      "capital_gain [(-99.999, 9999.9], (9999.9, 19999.8], (29999.7, 39999.6], (19999.8, 29999.7], (89999.1, 99999.0], (39999.6, 49999.5]]\n",
      "Categories (6, interval[float64]): [(-99.999, 9999.9] < (9999.9, 19999.8] < (19999.8, 29999.7] < (29999.7, 39999.6] < (39999.6, 49999.5] < (89999.1, 99999.0]]\n"
     ]
    }
   ],
   "source": [
    "clf = Classification()\n",
    "\n",
    "# convert train label to dataframe\n",
    "label = clf.train_label.values.ravel()\n",
    "df_label = pd.DataFrame(data=label,columns=['income'])\n",
    "df_label.shape\n",
    "\n",
    "# train data\n",
    "df_data = clf.train_data\n",
    "df_data = clf.preprocess(df_data,10)\n",
    "\n",
    "\n",
    "# test data\n",
    "test_df = clf.test_data\n",
    "test_df = clf.preprocess(test_df,10)\n",
    "\n",
    "\n",
    "\n",
    "# encode both datas\n",
    "encoded_df = clf.encode_df(df_data)\n",
    "encoded_test_df = clf.encode_df(test_df)\n",
    "\n",
    "\n",
    "\n",
    "# finds correlation between features\n",
    "temp_df = pd.concat([encoded_df,clf.train_label],axis=1,sort=False)\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "# corr = temp_df.corr()\n",
    "# sns.heatmap(corr, annot=True, cmap=plt.cm.Reds)\n",
    "\n",
    "#Correlation with output variable\n",
    "cor_target = abs(corr[\"income\"])\n",
    "\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.2]\n",
    "selected = list(dict(relevant_features))\n",
    "selected = selected[:-1]\n",
    "print(selected)\n",
    "\n",
    "\n",
    "for i in selected:\n",
    "    print(i,df_data[i].unique())\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_df[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_test_df[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = pd.get_dummies(encoded_df[selected],prefix_sep='_',columns=selected)\n",
    "# for i in selected:\n",
    "#     tmp = pd.get_dummies(encoded_df,prefix=[i], prefix_sep='_',columns = [i], drop_first=True)\n",
    "# print(\"train data shape: \",tmp.shape)\n",
    "# for i in selected:\n",
    "#     tmp1[i] = pd.get_dummies(encoded_test_df,prefix=[i], prefix_sep='_', columns = [i], drop_first=True)\n",
    "# print(\"test data shape: \",tmp.shape)\n",
    "# final_train, final_test = tmp.align(tmp1, join='inner', axis=1)  # inner join\n",
    "# print(\"final train data : {}\\nfinal test data: {}\".format(final_train.shape,final_test.shape))\n",
    "# print(encoded_df.capital_gain.unique())\n",
    "# tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:  (32561, 36)\n",
      "train data shape:  (16281, 36)\n",
      "final train data : (32561, 36)\n",
      "final test data: (16281, 36)\n"
     ]
    }
   ],
   "source": [
    "final_train,final_test = clf.panda_onehotencode(encoded_df,encoded_test_df,selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_0</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>age_6</th>\n",
       "      <th>age_7</th>\n",
       "      <th>age_8</th>\n",
       "      <th>age_9</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_4</th>\n",
       "      <th>relationship_5</th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>capital_gain_0</th>\n",
       "      <th>capital_gain_1</th>\n",
       "      <th>capital_gain_2</th>\n",
       "      <th>capital_gain_3</th>\n",
       "      <th>capital_gain_4</th>\n",
       "      <th>capital_gain_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32559</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_0  age_1  age_2  age_3  age_4  age_5  age_6  age_7  age_8  age_9  \\\n",
       "0          0      0      0      1      0      0      0      0      0      0   \n",
       "1          0      0      0      0      1      0      0      0      0      0   \n",
       "2          0      0      1      0      0      0      0      0      0      0   \n",
       "3          0      0      0      0      1      0      0      0      0      0   \n",
       "4          0      1      0      0      0      0      0      0      0      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "32556      0      1      0      0      0      0      0      0      0      0   \n",
       "32557      0      0      0      1      0      0      0      0      0      0   \n",
       "32558      0      0      0      0      0      1      0      0      0      0   \n",
       "32559      1      0      0      0      0      0      0      0      0      0   \n",
       "32560      0      0      0      0      1      0      0      0      0      0   \n",
       "\n",
       "       ...  relationship_4  relationship_5  sex_0  sex_1  capital_gain_0  \\\n",
       "0      ...               0               0      0      1               1   \n",
       "1      ...               0               0      0      1               1   \n",
       "2      ...               0               0      0      1               1   \n",
       "3      ...               0               0      0      1               1   \n",
       "4      ...               0               1      1      0               1   \n",
       "...    ...             ...             ...    ...    ...             ...   \n",
       "32556  ...               0               1      1      0               1   \n",
       "32557  ...               0               0      0      1               1   \n",
       "32558  ...               1               0      1      0               1   \n",
       "32559  ...               0               0      0      1               1   \n",
       "32560  ...               0               1      1      0               0   \n",
       "\n",
       "       capital_gain_1  capital_gain_2  capital_gain_3  capital_gain_4  \\\n",
       "0                   0               0               0               0   \n",
       "1                   0               0               0               0   \n",
       "2                   0               0               0               0   \n",
       "3                   0               0               0               0   \n",
       "4                   0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "32556               0               0               0               0   \n",
       "32557               0               0               0               0   \n",
       "32558               0               0               0               0   \n",
       "32559               0               0               0               0   \n",
       "32560               1               0               0               0   \n",
       "\n",
       "       capital_gain_5  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "32556               0  \n",
       "32557               0  \n",
       "32558               0  \n",
       "32559               0  \n",
       "32560               0  \n",
       "\n",
       "[32561 rows x 36 columns]"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.826040227237832"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize train and test data\n",
    "df_norm = clf.normalize_data(encoded_df[selected])\n",
    "df_test_norm = clf.normalize_data(encoded_test_df[selected])\n",
    "\n",
    "# convert from numpy to dataframe\n",
    "df_norm = pd.DataFrame(data=df_norm,columns=selected)\n",
    "df_test_norm = pd.DataFrame(data=df_test_norm,columns=selected)\n",
    "\n",
    "# print(df_norm)\n",
    "clf.take_model(ensemble.RandomForestClassifier)\n",
    "clf.plain_training(final_train,label,final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score of above implementation\n",
    "# print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique count of prediction\n",
    "# clf.generate_submission(gradient.predict(df_test_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running CV with different method and in the order accuracy score\n",
    "\n",
    "Below k-fold CV uses \n",
    "\n",
    "`cross_val_score`\n",
    "\n",
    "`cross_val_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(pred):\n",
    "    df = pd.read_csv('submission1.csv')\n",
    "    mis_classified = 0\n",
    "    for i in range(len(pred)):\n",
    "        if(df['Category'][i] != pred[i]):\n",
    "            mis_classified += 1\n",
    "    return mis_classified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  [0.8513559229095312, 0.8571604723780971, 0.8596481024797534, 0.8615829041978493, 0.8628113752452897, 0.8641626690621252, 0.8646233372158401, 0.864623348534607, 0.8647769526906047, 0.8650533258518548]\n",
      "fitting now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final prediction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1522"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gradient = ensemble.GradientBoostingClassifier(n_estimators=500)\n",
    "# cross_val_score(gradient,X_ohe,label,cv=3)\n",
    "gdb_score,gdb_pred = clf.kfold_cw(gradient,final_train,label,final_test,3)\n",
    "compare(gdb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient.fit(X_ohe,label)\n",
    "pred = gradient.predict(test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostClassifier\n",
    "adaboost = ensemble.AdaBoostClassifier(n_estimators=500,learning_rate= 1)\n",
    "\n",
    "ada_score,ada_pred = clf.kfold_cw(adaboost,df_norm,df_label,df_test_norm,10)\n",
    "print(\"adaboost \", compare(ada_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "rdmforest = ensemble.RandomForestClassifier(n_estimators=200,min_samples_split=2,min_samples_leaf=4,max_depth=10,bootstrap=True)\n",
    "\n",
    "rdfst_score,rdfst_pred = clf.kfold_cw(rdmforest,df_norm,df_label,df_test_norm,3)\n",
    "compare(rdfst_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmforest = ensemble.RandomForestClassifier(n_estimators=200,bootstrap=True)\n",
    "\n",
    "rdfst_score1,rdfst_pred1 = clf.kfold_cw(rdmforest,df_norm,df_label,df_test_norm,10)\n",
    "compare(rdfst_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra tree classifier\n",
    "extratree = ensemble.ExtraTreesClassifier(n_estimators=100, max_depth=None,min_samples_split=2, random_state=0)\n",
    "extra_score, extra_pred = clf.kfold_cw(extratree,df_norm,df_label,df_test_norm,3)\n",
    "compare(extra_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "NB = naive_bayes.GaussianNB()\n",
    "nb_score,nb_pred = clf.kfold_cw(NB,df_norm,df_label,df_test_norm,10)\n",
    "compare(nb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma='auto')\n",
    "svc_score,svc_pred = clf.kfold_cw(svc,df_norm,df_label,df_test_norm,3)\n",
    "compare(svc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "decisiontree = tree.DecisionTreeClassifier(max_depth=None,min_samples_split=2,random_state=0)\n",
    "tree_score,tree_pred = clf.kfold_cw(decisiontree,df_norm,df_label,df_test_norm,10)\n",
    "compare(tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "# lasso = linear_model.Lasso(alpha=0.7)\n",
    "# lasso_score, lasso_pred = clf.kfold_cw(lasso,df_norm,df_label,df_test_norm,3)\n",
    "# compare(lasso_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging = ensemble.BaggingClassifier(n_estimators=10,base_estimator=SVC(gamma='auto'),random_state=0)\n",
    "# score,pred = clf.kfold_cw(bagging,df_norm,df_label,df_test_norm,3)\n",
    "\n",
    "# accuracy of [0.82725263 0.83185922 0.83165945]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normalization and 3 kfold cv, the random forest with n_estimators=1600,min_samples_split=2,min_samples_leaf=4,max_depth=10,bootstrap=True parameters \n",
    "\n",
    "gave this accuracy scores\n",
    "\n",
    "[0.83618942 0.83812419 0.84059707]\n",
    "\n",
    "And with minmaxscaler and svr model ```best_svr = SVR(kernel='rbf',gamma='auto') ```, we got\n",
    "\n",
    "[0.85185185 0.85756403 0.86289505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ada_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(extra_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(rdfst_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(gdb_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/411290/how-to-use-a-cross-validated-model-for-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.generate_submission(gradient.predict(df_test_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "pred = []\n",
    "step_size = [0.1,0.3,0.5,0.6,0.7,0.8,0.9,1,1.5,1.8]\n",
    "mis_classified = []\n",
    "actual_pred = []\n",
    "for n,s in zip(random_grid['n_estimators'],step_size):\n",
    "    adaboost = ensemble.AdaBoostClassifier(n_estimators=n,learning_rate=s)\n",
    "\n",
    "    ada_score,ada_pred = clf.kfold_cw(adaboost,df_norm,df_label,df_test_norm,3)\n",
    "    score.append(ada_score)\n",
    "    pred.append(np.unique(ada_pred,return_counts=True))\n",
    "    mis_classified.append(compare(ada_pred))\n",
    "    actual_pred.append(ada_pred)\n",
    "    print(ada_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.DataFrame()\n",
    "data_info['n_estimators'] = random_grid['n_estimators']\n",
    "data_info['step_size'] = step_size\n",
    "data_info['score'] = score\n",
    "data_info['pred_count'] = pred\n",
    "data_info['mis_classified'] = mis_classified\n",
    "data_info['actual_pred'] = actual_pred\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(actual_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info[data_info.score == data_info['score'].max()]mis_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = []\n",
    "pred1 = []\n",
    "step_size = [0.1,0.3,0.5,0.6,0.7,0.8,0.9,1,1.5,1.8]\n",
    "for n,s in zip(random_grid['n_estimators'],step_size):\n",
    "    gradient = ensemble.GradientBoostingClassifier(n_estimators=n,learning_rate=s)\n",
    "    gdb_score,gdb_pred = clf.kfold_cw(gradient,df_norm,df_label,df_test_norm,3)\n",
    "    print(gdb_score)\n",
    "    score1.append(gdb_score)\n",
    "    pred1.append(np.unique(gdb_pred,return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# # First create the base model to tune\n",
    "# rf = RandomForestRegressor()\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(df_norm, df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
