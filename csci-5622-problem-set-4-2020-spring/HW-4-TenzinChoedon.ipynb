{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = ['age','workclass','fnlwgt','education','education_num','marital-status',\n",
    "               'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "               'hours-per-week','native-country']\n",
    "df = pd.read_csv('train-features.csv',names=columns_name,header=None,na_values=' ?')\n",
    "df['income'] = pd.read_csv('train-output.csv') #Binary (0 means <=50K, 1 means >50K)\n",
    "df.columns = df.columns.str.replace('-','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
       "       ' Local-gov', nan, ' Self-emp-inc', ' Without-pay',\n",
       "       ' Never-worked'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['workclass'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.native_country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.model = None\n",
    "        self.columns_name = ['age','workclass','fnlwgt','education','education-num',\n",
    "                                       'marital-status','occupation','relationship','race','sex',\n",
    "                                       'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "        self.train_data = pd.read_csv('train-features.csv',names=self.columns_name,header=None,na_values=' ?')\n",
    "        self.train_data.columns = self.train_data.columns.str.replace('-','_')\n",
    "        self.train_label = pd.read_csv('train-output.csv',names=['income'],header=None) #Binary (0 means <=50K, 1 means >50K)\n",
    "#         self.train_label = self.train_label.values.ravel()\n",
    "        self.test_data = pd.read_csv('test-features.csv',names=self.columns_name,header=None,na_values=' ?')\n",
    "        self.test_data.columns = self.test_data.columns.str.replace('-','_')\n",
    "        self.x_train = None\n",
    "        self.x_test  = None\n",
    "        self.y_train = None\n",
    "        self.y_test  = None\n",
    "    def preprocess(self,df,bins):\n",
    "        '''\n",
    "        Cleans df and performs feature engineering.\n",
    "        '''\n",
    "        \n",
    "        for i in df.columns:\n",
    "            \n",
    "            df[i] = df[i].fillna(list(dict(df[i].dropna().value_counts()))[0]) # replace nan values with most commone values of it's column\n",
    "        # category\n",
    "        df['education'] = df['education'].str.replace('Preschool', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('10th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('11th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('12th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('1st-4th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('5th-6th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('7th-8th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('9th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('HS-Grad', 'HighGrad')\n",
    "        df['education'] = df['education'].str.replace('HS-grad', 'HighGrad')\n",
    "        df['education'] = df['education'].str.replace('Some-college', 'CommunityCollege')\n",
    "        df['education'] = df['education'].str.replace('Assoc-acdm', 'CommunityCollege')\n",
    "        df['education'] = df['education'].str.replace('Assoc-voc', 'CommunityCollege')\n",
    "        \n",
    "        # [' Never-married', ' Married-civ-spouse', ' Divorced',' Married-spouse-absent', ' Separated', ' Married-AF-spouse',\n",
    "        # ' Widowed']\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Never-married','notMarried')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Married-spouse-absent','notMarried')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Seperated','notMarried')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Divorced','notMarried')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Widowed','notMarried')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Married-AF-spouse','Married')\n",
    "        df['marital_status'] = df['marital_status'].str.replace('Married-civ-spouse','Married')\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # df['workclass'] doesn't effect performance\n",
    "#         '''\n",
    "#         ' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
    "#        ' Local-gov', nan, ' Self-emp-inc', ' Without-pay',\n",
    "#        ' Never-worked']\n",
    "#         '''\n",
    "#         df['workclass'] = df['workclass'].str.replace('Never-worked','LowIncome')\n",
    "#         df['workclass'] = df['workclass'].str.replace('Without-pay','LowIncome')\n",
    "#         df['workclass'] = df['workclass'].str.replace('State-gov','Govt')\n",
    "#         df['workclass'] = df['workclass'].str.replace('Federal-gov','Govt')\n",
    "#         df['workclass'] = df['workclass'].str.replace('Local-gov','Govt')\n",
    "        \n",
    "        \n",
    "        # Binning\n",
    "#         education_num = pd.cut(df.education_num,bins=[0,8,9,12,13,14,15,16],labels=[0,1,2,3,4,5,6])\n",
    "#         df['education_num'] = education_num\n",
    "#         CG = pd.cut(df.capital_gain,bins=[-1,7700,1000000],labels=[1,2]) # [low gain,high gain]\n",
    "#         df['capital_gain'] = CG\n",
    "        \n",
    "#         CL = pd.cut(df.capital_loss, bins=[-1,1900,1000000],labels= [1,0]) # [low loss,high loss]\n",
    "#         df['capital_loss'] = CL\n",
    "        \n",
    "        # Create categories for continuous values. Run it only once\n",
    "#         age = pd.cut(df.age,bins=[0,18,27,50,100],labels=[0,1,2,3]) # ['HighGrad','Bachelor','Grad','others'] ==> https://en.wikipedia.org/wiki/Education_in_the_United_States\n",
    "        \n",
    "#         age = pd.cut(df.age,bins)  \n",
    "        hours = pd.cut(df.hours_per_week,bins=[0,20,40,49,100],labels=['PT','FT','OverTime','TwoJobs'])\n",
    "        df['hours_per_week'] = hours\n",
    "#         replace old column with new column with category values\n",
    "#         df['age'] = age\n",
    "        \n",
    "        return df\n",
    "    def take_model(self,model):\n",
    "        '''\n",
    "        Takes in model.\n",
    "        '''\n",
    "        self.model = model\n",
    "        \n",
    "        \n",
    "    def plain_training(self,df_data,df_label,test_df):\n",
    "        '''\n",
    "        It trains model once and returns accuracy score\n",
    "        '''\n",
    "        self.x_train,self.x_test, self.y_train, self.y_test = model_selection.train_test_split(df_data,df_label,test_size=0.2,random_state=2)\n",
    "        self.x_train = self.normalize_data(self.x_train)\n",
    "        self.x_test = self.normalize_data(self.x_test)\n",
    "        test = self.normalize_data(test_df)\n",
    "        clf = self.model()\n",
    "        clf.fit(self.x_train,self.y_train)\n",
    "        y_pred = clf.predict(test)\n",
    "        \n",
    "        return clf.score(self.x_test,self.y_test)\n",
    "    \n",
    "    def generate_submission(self, y_pred):\n",
    "        '''\n",
    "        Saves submission in the right format.\n",
    "        '''\n",
    "        pred_df = pd.DataFrame()\n",
    "        pred_df['Id'] = np.arange(0,len(y_pred))\n",
    "        pred_df['Category'] = y_pred\n",
    "        pred_df.to_csv('submission.csv',index=False)\n",
    "        \n",
    "    def encode_df(self,df):\n",
    "        '''\n",
    "        Encode string values in dataframe into numbers.\n",
    "        '''\n",
    "        \n",
    "        return df.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    def normalize_data(self, X):\n",
    "        # TO DO: Normalize the feature values of dataset X using the mean and standard deviation of the respective features \n",
    "        # min_max has is better than robustscaler\n",
    "#         min_max_scaler = preprocessing.MinMaxScaler() \n",
    "#         X = min_max_scaler.fit_transform(X)\n",
    "        \n",
    "#         scaler = preprocessing.RobustScaler()\n",
    "#         X = scaler.fit_transform(X)\n",
    "        # scale is better than min_max\n",
    "        X = preprocessing.scale(X)\n",
    "        # quantile_transformer did better than scale\n",
    "#         quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "#         X = quantile_transformer.fit_transform(X)\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def panda_onehotencode(self,train,test,selected):\n",
    "        '''\n",
    "        One hot encode train and test data. Then make sure they have same column amount.\n",
    "        # https://stackoverflow.com/questions/58101126/using-scikit-learn-onehotencoder-with-a-pandas-dataframe\n",
    "        https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
    "        \n",
    "        returns train, test\n",
    "        '''\n",
    "        tmp = pd.get_dummies(train[selected],prefix_sep='_',columns=selected)\n",
    "        print(\"train data shape: \",tmp.shape)\n",
    "\n",
    "        tmp1 = pd.get_dummies(test[selected],prefix_sep='_',columns=selected)\n",
    "        print(\"test data shape: \",tmp1.shape)\n",
    "\n",
    "        final_train, final_test = tmp.align(tmp1, join='inner', axis=1)  # inner join\n",
    "        print(\"final train data : {}\\nfinal test data: {}\".format(final_train.shape,final_test.shape))\n",
    "        return final_train,final_test\n",
    "    \n",
    "    def kfold_cw(self,model,df_data,df_label,df_test,niter):\n",
    "        scores = cross_val_score(model,df_data,df_label.values.ravel(),cv=niter)\n",
    "        print(\"Accuracy score: \",scores)\n",
    "#         pred  = cross_val_predict(model,df_data,df_label,cv=niter)\n",
    "        print('fitting now')\n",
    "        final_model = model.fit(df_data,df_label.values.ravel())\n",
    "        print('predicting now')\n",
    "        new_pred = model.predict(df_test)\n",
    "        print('acc: ',np.mean(scores))\n",
    "        return np.mean(scores),new_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 14) (16281, 14)\n"
     ]
    }
   ],
   "source": [
    "clf = Classification()\n",
    "\n",
    "# convert train label to dataframe\n",
    "label = clf.train_label.values.ravel()\n",
    "df_label = pd.DataFrame(data=label,columns=['income'])\n",
    "df_label.shape\n",
    "\n",
    "# train data\n",
    "df_data = clf.train_data\n",
    "df_data = clf.preprocess(df_data,10)\n",
    "\n",
    "\n",
    "# test data\n",
    "test_df = clf.test_data\n",
    "print(df_data.shape,test_df.shape)\n",
    "test_df = clf.preprocess(test_df,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 9) (16281, 9)\n",
      "(32561, 14) (16281, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>capital_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.721506</td>\n",
       "      <td>0.183684</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0.146294</td>\n",
       "      <td>0.525025</td>\n",
       "      <td>0.291792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908988</td>\n",
       "      <td>0.259760</td>\n",
       "      <td>0.735736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407489</td>\n",
       "      <td>0.670671</td>\n",
       "      <td>0.565065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188438</td>\n",
       "      <td>0.020521</td>\n",
       "      <td>0.565065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16276</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685686</td>\n",
       "      <td>0.550551</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16277</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.891671</td>\n",
       "      <td>0.955956</td>\n",
       "      <td>0.291792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16278</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0.946008</td>\n",
       "      <td>0.525025</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16279</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133620</td>\n",
       "      <td>0.670671</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517697</td>\n",
       "      <td>0.444945</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  education  marital_status  occupation  relationship  race  \\\n",
       "0              3          6               2           6             3     2   \n",
       "1              3          3               0           4             0     4   \n",
       "2              1          1               0          10             0     4   \n",
       "3              3          1               0           6             0     2   \n",
       "4              3          1               2           9             3     4   \n",
       "...          ...        ...             ...         ...           ...   ...   \n",
       "16276          3          0               2           9             1     4   \n",
       "16277          3          3               2           9             2     2   \n",
       "16278          3          0               0           9             0     4   \n",
       "16279          3          0               2           0             3     1   \n",
       "16280          4          0               0           3             0     4   \n",
       "\n",
       "       sex  native_country  hours_per_week    fnlwgt       age  education_num  \\\n",
       "0        1              37               0  0.721506  0.183684       0.099600   \n",
       "1        1              37               3  0.146294  0.525025       0.291792   \n",
       "2        1              37               0  0.908988  0.259760       0.735736   \n",
       "3        1              37               0  0.407489  0.670671       0.565065   \n",
       "4        0              37               0  0.188438  0.020521       0.565065   \n",
       "...    ...             ...             ...       ...       ...            ...   \n",
       "16276    0              37               0  0.685686  0.550551       0.834334   \n",
       "16277    1              37               0  0.891671  0.955956       0.291792   \n",
       "16278    1              37               3  0.946008  0.525025       0.834334   \n",
       "16279    1              37               0  0.133620  0.670671       0.834334   \n",
       "16280    1              37               3  0.517697  0.444945       0.834334   \n",
       "\n",
       "       capital_loss  capital_gain  \n",
       "0               0.0      0.000000  \n",
       "1               0.0      0.000000  \n",
       "2               0.0      0.000000  \n",
       "3               0.0      0.969469  \n",
       "4               0.0      0.000000  \n",
       "...             ...           ...  \n",
       "16276           0.0      0.000000  \n",
       "16277           0.0      0.000000  \n",
       "16278           0.0      0.000000  \n",
       "16279           0.0      0.954687  \n",
       "16280           0.0      0.000000  \n",
       "\n",
       "[16281 rows x 14 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df_data.head() )\n",
    "categorical_feature_mask = df_data.dtypes==object # gets features with string or object value\n",
    "categorical_feature_mask\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = df_data.columns[categorical_feature_mask].tolist()\n",
    "categorical_cols.append('hours_per_week')\n",
    "# categorical_cols.append('education_num')\n",
    "# categorical_cols.append('capital_gain')\n",
    "# categorical_cols.append('capital_loss')\n",
    "\n",
    "# categorical_cols\n",
    "non_categorical_cols = list(set(df_data.columns) - set(categorical_cols))\n",
    "\n",
    "# encode categorical data\n",
    "encoded = clf.encode_df(df_data[categorical_cols])\n",
    "test_encoded = clf.encode_df(test_df[categorical_cols])\n",
    "\n",
    "# encoded,test_encoded = clf.panda_onehotencode(df_data,test_df,categorical_cols)\n",
    "print(encoded.shape,test_encoded.shape)\n",
    "encoded\n",
    "\n",
    "# min_max has is better than robustscaler\n",
    "# min_max_scaler = preprocessing.MinMaxScaler() \n",
    "# X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# scale is better than min_max\n",
    "# scale = preprocessing.scale(df_data[non_categorical_cols])\n",
    "# x_test = s\n",
    "# quantile_transformer did better than scale\n",
    "# quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "# X = quantile_transformer.fit_transform(X)\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "X_train_trans = quantile_transformer.fit_transform(df_data[non_categorical_cols])\n",
    "X_test_trans = quantile_transformer.transform(test_df[non_categorical_cols])\n",
    "\n",
    "# Normalized continous data\n",
    "# normalized = clf.normalize_data(df_data[non_categorical_cols])\n",
    "normalized = pd.DataFrame(data=X_train_trans,columns=non_categorical_cols)\n",
    "\n",
    "# test_normalized = clf.normalize_data(test_df[non_categorical_cols])\n",
    "test_normalized = pd.DataFrame(data=X_test_trans,columns=non_categorical_cols)\n",
    "\n",
    "# Concat both data\n",
    "final_train = pd.concat([encoded,normalized],axis=1)\n",
    "final_test = pd.concat([test_encoded,test_normalized],axis=1)\n",
    "print(final_train.shape,final_test.shape)\n",
    "final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_train,final_test = clf.panda_onehotencode(final_train,final_test,selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484569322892677"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # normalize train and test data\n",
    "# df_norm = clf.normalize_data(encoded_df[selected])\n",
    "# df_test_norm = clf.normalize_data(encoded_test_df[selected])\n",
    "\n",
    "# # convert from numpy to dataframe\n",
    "# df_norm = pd.DataFrame(data=df_norm,columns=selected)\n",
    "# df_test_norm = pd.DataFrame(data=df_test_norm,columns=selected)\n",
    "\n",
    "# print(df_norm)\n",
    "clf.take_model(ensemble.GradientBoostingClassifier)\n",
    "clf.plain_training(final_train,label,final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique count of prediction\n",
    "# clf.generate_submission(gradient.predict(df_test_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running CV with different method and in the order accuracy score\n",
    "\n",
    "Below k-fold CV uses \n",
    "\n",
    "`cross_val_score`\n",
    "\n",
    "`cross_val_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  [0.86797494 0.87221301 0.87579471]\n",
      "fitting now\n",
      "predicting now\n",
      "acc:  0.8719942200943166\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gradient = ensemble.GradientBoostingClassifier(n_estimators=200,learning_rate=0.2,min_samples_split=10,max_features='auto',min_samples_leaf=1)\n",
    "gdb_score,gdb_pred = clf.kfold_cw(gradient,final_train,df_label,final_test,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  [0.86484245 0.86944905 0.8725698 ]\n",
      "fitting now\n",
      "predicting now\n",
      "acc:  0.8689537672684838\n",
      "Accuracy score:  [0.86705362 0.87138382 0.87468903]\n",
      "fitting now\n",
      "predicting now\n",
      "acc:  0.8710421561644272\n",
      "Accuracy score:  [0.86742215 0.87193661 0.87514973]\n",
      "fitting now\n",
      "predicting now\n",
      "acc:  0.8715028299775255\n",
      "Accuracy score:  [0.86668509 0.87037037 0.87625541]\n",
      "fitting now\n",
      "predicting now\n",
      "acc:  0.8711036255578052\n",
      "Accuracy score:  [0.86981758 0.86963331 0.87422832]\n",
      "fitting now\n",
      "predicting now\n",
      "acc:  0.8712264058818245\n",
      "['marital_status', 'occupation', 'hours_per_week', 'fnlwgt', 'age', 'education_num', 'capital_loss', 'capital_gain']\n",
      "['workclass', 'marital_status', 'occupation', 'hours_per_week', 'fnlwgt', 'age', 'education_num', 'capital_loss', 'capital_gain']\n",
      "['workclass', 'marital_status', 'occupation', 'relationship', 'hours_per_week', 'fnlwgt', 'age', 'education_num', 'capital_loss', 'capital_gain']\n",
      "['workclass', 'marital_status', 'occupation', 'relationship', 'native_country', 'hours_per_week', 'fnlwgt', 'age', 'education_num', 'capital_loss', 'capital_gain']\n",
      "['workclass', 'marital_status', 'occupation', 'relationship', 'sex', 'native_country', 'hours_per_week', 'fnlwgt', 'age', 'education_num', 'capital_loss', 'capital_gain']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>f_pred</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[marital_status, occupation, hours_per_week, f...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.868954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[workclass, marital_status, occupation, hours_...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.871042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[workclass, marital_status, occupation, relati...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.871503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[workclass, marital_status, occupation, relati...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.871104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[workclass, marital_status, occupation, relati...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.871226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  \\\n",
       "0  [marital_status, occupation, hours_per_week, f...   \n",
       "1  [workclass, marital_status, occupation, hours_...   \n",
       "2  [workclass, marital_status, occupation, relati...   \n",
       "3  [workclass, marital_status, occupation, relati...   \n",
       "4  [workclass, marital_status, occupation, relati...   \n",
       "\n",
       "                                              f_pred       acc  \n",
       "0  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...  0.868954  \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...  0.871042  \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...  0.871503  \n",
       "3  [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...  0.871104  \n",
       "4  [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...  0.871226  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = list(final_train.columns)\n",
    "acc = []\n",
    "f_pred = []\n",
    "feat = []\n",
    "for i in range(8,13):\n",
    "    # run RFE\n",
    "    selector = RFE(gradient, i, step=1)\n",
    "    selector = selector.fit(final_train, df_label.values.ravel())\n",
    "\n",
    "    rank = selector.ranking_\n",
    "    \n",
    "    # selected those top tank features\n",
    "    f_feature = []\n",
    "    for r,f in zip(rank,feature):\n",
    "        if(r == 1):\n",
    "            f_feature.append(f)\n",
    "    feat.append(f_feature)\n",
    "    # train model on new selected features\n",
    "    gradient = ensemble.GradientBoostingClassifier(n_estimators=200,learning_rate=0.2,min_samples_split=10,max_features='auto',min_samples_leaf=1)\n",
    "    gdb_score,gdb_pred = clf.kfold_cw(gradient,final_train[f_feature],df_label,final_test[f_feature],3)\n",
    "    acc.append(gdb_score)\n",
    "    f_pred.append(gdb_pred)\n",
    "\n",
    "data_info = pd.DataFrame()\n",
    "data_info['feature'] = feat\n",
    "data_info['f_pred'] = f_pred\n",
    "data_info['acc'] = acc\n",
    "for f in data_info.feature:\n",
    "    print(f)\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare(pred):\n",
    "    df = pd.read_csv('submission1.csv') #last submission\n",
    "    mis_classified = 0\n",
    "    for i in range(len(pred)):\n",
    "#         if(df['Category'][i] == 1):\n",
    "        if(df['Category'][i] != pred[i]):\n",
    "            mis_classified += 1 # last best was 290 (505 with above if statement) mis_classified or close to this\n",
    "    return mis_classified\n",
    "compare(gdb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634\n",
      "545\n",
      "505\n",
      "1211\n",
      "1235\n"
     ]
    }
   ],
   "source": [
    "for i in data_info.f_pred:\n",
    "    print(compare(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([12706,  3575]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_info.f_pred[3],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.generate_submission(data_info.f_pred[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  [0.86355261 0.86668509 0.86906846]\n",
      "fitting now\n",
      "final prediction\n",
      "acc:  0.8664353869068341\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "adaboost = ensemble.AdaBoostClassifier(n_estimators=200,learning_rate= 1)\n",
    "\n",
    "ada_score,ada_pred = clf.kfold_cw(adaboost,final_train,df_label,final_test,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  [0.86014373 0.86733002 0.86888418]\n",
      "fitting now\n",
      "final prediction\n",
      "acc:  0.8654526406295525\n",
      "Accuracy score:  [0.8615257  0.86650083 0.86943702]\n",
      "fitting now\n",
      "final prediction\n",
      "acc:  0.8658211853394148\n",
      "Accuracy score:  [0.86134144 0.86594804 0.86943702]\n",
      "fitting now\n",
      "final prediction\n",
      "acc:  0.86557550018494\n",
      "Accuracy score:  [0.86318408 0.8664087  0.86952916]\n",
      "fitting now\n",
      "final prediction\n",
      "acc:  0.8663739797666742\n",
      "['workclass', 'marital_status', 'occupation', 'relationship', 'hours_per_week', 'education_num', 'fnlwgt', 'age', 'capital_gain', 'capital_loss']\n",
      "['workclass', 'marital_status', 'occupation', 'relationship', 'native_country', 'hours_per_week', 'education_num', 'fnlwgt', 'age', 'capital_gain', 'capital_loss']\n",
      "['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'native_country', 'hours_per_week', 'education_num', 'fnlwgt', 'age', 'capital_gain', 'capital_loss']\n",
      "['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'sex', 'native_country', 'hours_per_week', 'education_num', 'fnlwgt', 'age', 'capital_gain', 'capital_loss']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>f_pred</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[workclass, marital_status, occupation, relati...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.865453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[workclass, marital_status, occupation, relati...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.865821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[workclass, education, marital_status, occupat...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>0.865576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[workclass, education, marital_status, occupat...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.866374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  \\\n",
       "0  [workclass, marital_status, occupation, relati...   \n",
       "1  [workclass, marital_status, occupation, relati...   \n",
       "2  [workclass, education, marital_status, occupat...   \n",
       "3  [workclass, education, marital_status, occupat...   \n",
       "\n",
       "                                              f_pred       acc  \n",
       "0  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ...  0.865453  \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  0.865821  \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, ...  0.865576  \n",
       "3  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ...  0.866374  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = list(final_train.columns)\n",
    "acc = []\n",
    "f_pred = []\n",
    "feat = []\n",
    "for i in range(10,14):\n",
    "    # run RFE\n",
    "    selector = RFE(gradient, i, step=1)\n",
    "    selector = selector.fit(final_train, df_label.values.ravel())\n",
    "\n",
    "    rank = selector.ranking_\n",
    "    \n",
    "    # selected those top tank features\n",
    "    f_feature = []\n",
    "    for r,f in zip(rank,feature):\n",
    "        if(r == 1):\n",
    "            f_feature.append(f)\n",
    "    feat.append(f_feature)\n",
    "    # train model on new selected features\n",
    "    adaboost = ensemble.AdaBoostClassifier(n_estimators=200,learning_rate= 1)\n",
    "\n",
    "    ada_score,ada_pred = clf.kfold_cw(adaboost,final_train[f_feature],df_label,final_test[f_feature],3)\n",
    "    acc.append(ada_score)\n",
    "    f_pred.append(ada_pred)\n",
    "\n",
    "data_info = pd.DataFrame()\n",
    "data_info['feature'] = feat\n",
    "data_info['f_pred'] = f_pred\n",
    "data_info['acc'] = acc\n",
    "for f in data_info.feature:\n",
    "    print(f)\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(ada_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last submission\n",
    "f = pd.read_csv('submission.csv')\n",
    "compare(f.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.generate_submission(gdb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_scores1 = pd.Series(adaboost.feature_importances_, index=final_train.columns).sort_values(ascending=False)\n",
    "# list(dict(feature_scores1[feature_scores1 > 0.009]))\n",
    "\n",
    "# final_train = final_train[list(dict(feature_scores1[feature_scores1 > 0.009]))]\n",
    "# final_train\n",
    "\n",
    "# feature_scores = pd.Series(adaboost.feature_importances_, index=final_test.columns).sort_values(ascending=False)\n",
    "# list(dict(feature_scores[feature_scores > 0.009]))\n",
    "\n",
    "# final_test = final_test[list(dict(feature_scores[feature_scores > 0.009]))]\n",
    "# final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "rdmforest = ensemble.RandomForestClassifier(n_estimators=200,min_samples_split=2,min_samples_leaf=4,max_depth=10,bootstrap=True)\n",
    "\n",
    "rdfst_score,rdfst_pred = clf.kfold_cw(rdmforest,final_train,df_label,final_test,3)\n",
    "compare(rdfst_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmforest = ensemble.RandomForestClassifier(n_estimators=200,bootstrap=False)\n",
    "\n",
    "rdfst_score1,rdfst_pred1 = clf.kfold_cw(rdmforest,final_train,df_label,final_test,10)\n",
    "compare(rdfst_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra tree classifier\n",
    "extratree = ensemble.ExtraTreesClassifier(n_estimators=100, max_depth=None,min_samples_split=2, random_state=0)\n",
    "extra_score, extra_pred = clf.kfold_cw(extratree,final_train,df_label,final_test,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Naive Bayes\n",
    "# NB = naive_bayes.GaussianNB()\n",
    "# nb_score,nb_pred = clf.kfold_cw(NB,final_train,df_label,final_test,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma='auto')\n",
    "svc_score,svc_pred = clf.kfold_cw(svc,final_train,df_label,final_test,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.generate_submission(gdb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "decisiontree = tree.DecisionTreeClassifier(max_depth=None,min_samples_split=2,random_state=0)\n",
    "tree_score,tree_pred = clf.kfold_cw(decisiontree,final_train,df_label,final_test,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "# lasso = linear_model.Lasso(alpha=0.7)\n",
    "# lasso_score, lasso_pred = clf.kfold_cw(lasso,final_train,df_label,final_test,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = ensemble.BaggingClassifier(n_estimators=10,base_estimator=SVC(gamma='auto'),random_state=0)\n",
    "score,pred = clf.kfold_cw(bagging,final_train,df_label,final_test,3)\n",
    "\n",
    "# accuracy of [0.82725263 0.83185922 0.83165945]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normalization and 3 kfold cv, the random forest with n_estimators=1600,min_samples_split=2,min_samples_leaf=4,max_depth=10,bootstrap=True parameters \n",
    "\n",
    "gave this accuracy scores\n",
    "\n",
    "[0.83618942 0.83812419 0.84059707]\n",
    "\n",
    "And with minmaxscaler and svr model ```best_svr = SVR(kernel='rbf',gamma='auto') ```, we got\n",
    "\n",
    "[0.85185185 0.85756403 0.86289505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ada_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(extra_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(rdfst_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(gdb_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/411290/how-to-use-a-cross-validated-model-for-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.generate_submission(gradient.predict(final_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 400, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "pred = []\n",
    "step_size = [0.1,0.2,0.3,0.5,0.6,0.7,0.8,0.9,1,1.5,1.8]\n",
    "actual_pred = []\n",
    "mis_classified = []\n",
    "for n in range(2,10,3):\n",
    "    print(n)\n",
    "    gradient = ensemble.GradientBoostingClassifier(n_estimators=200,learning_rate=0.2,min_samples_split=10,max_features='auto',min_samples_leaf=1)\n",
    "    gdb_score,gdb_pred = clf.kfold_cw(gradient,final_train,df_label,final_test,n)\n",
    "    score.append(gdb_score)\n",
    "    pred.append(np.unique(gdb_pred,return_counts=True))\n",
    "    actual_pred.append(gdb_pred)\n",
    "    mis_classified.append(compare(gdb_pred))\n",
    "  \n",
    "for i in range(0,5,2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.DataFrame()\n",
    "# data_info['n_estimators'] = random_grid['n_estimators']\n",
    "# data_info['max_features'] = random_grid['max_features']\n",
    "# data_info['current'] = random_grid['n_estimators']\n",
    "# data_info['step_size'] = step_size\n",
    "data_info['score'] = score\n",
    "data_info['pred_count'] = pred\n",
    "data_info['mis_classified'] = mis_classified\n",
    "data_info['actual_pred'] = actual_pred\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info[data_info.score == data_info['score'].max()]mis_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = []\n",
    "pred1 = []\n",
    "step_size = [0.1,0.3,0.5,0.6,0.7,0.8,0.9,1,1.5,1.8]\n",
    "for n,s in zip(random_grid['n_estimators'],step_size):\n",
    "    gradient = ensemble.GradientBoostingClassifier(n_estimators=n,learning_rate=s)\n",
    "    gdb_score,gdb_pred = clf.kfold_cw(gradient,final_train,df_label,final_test,3)\n",
    "    print(gdb_score)\n",
    "    score1.append(gdb_score)\n",
    "    pred1.append(np.unique(gdb_pred,return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# # First create the base model to tune\n",
    "# rf = RandomForestRegressor()\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(final_train, df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
