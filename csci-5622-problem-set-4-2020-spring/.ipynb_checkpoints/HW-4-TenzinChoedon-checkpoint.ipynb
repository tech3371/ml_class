{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = ['age','workclass','fnlwgt','education','education-num','marital-status',\n",
    "               'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "               'hours-per-week','native-country']\n",
    "df = pd.read_csv('train-features.csv',names=columns_name,header=None,na_values=' ?')\n",
    "df['income'] = pd.read_csv('train-output.csv') #Binary (0 means <=50K, 1 means >50K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.model = None\n",
    "        self.columns_name = ['age','workclass','fnlwgt','education','education-num',\n",
    "                                       'marital-status','occupation','relationship','race','sex',\n",
    "                                       'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "        self.train_data = pd.read_csv('train-features.csv',names=self.columns_name,header=None,na_values=' ?')\n",
    "        self.train_data['income'] = pd.read_csv('train-output.csv') #Binary (0 means <=50K, 1 means >50K)\n",
    "        self.train_data = self.train_data.dropna()\n",
    "        self.test_data = pd.read_csv('test-features.csv',names=self.columns_name,header=None,na_values=' ?')\n",
    "        \n",
    "        self.x_train = None\n",
    "        self.x_test  = None\n",
    "        self.y_train = None\n",
    "        self.y_test  = None\n",
    "    def preprocess(self,df):\n",
    "        '''\n",
    "        Cleans df and performs feature engineering.\n",
    "        '''\n",
    "        # replace nan values with random values of it's column's value\n",
    "        for i in self.columns_name:\n",
    "            df[i] = df[i].fillna(np.random.choice(df[i].dropna().unique()))\n",
    "\n",
    "        # category\n",
    "        df['education'] = df['education'].str.replace('Preschool', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('10th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('11th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('12th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('1st-4th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('5th-6th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('7th-8th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('9th', 'dropout')\n",
    "        df['education'] = df['education'].str.replace('HS-Grad', 'HighGrad')\n",
    "        df['education'] = df['education'].str.replace('HS-grad', 'HighGrad')\n",
    "        df['education'] = df['education'].str.replace('Some-college', 'CommunityCollege')\n",
    "        df['education'] = df['education'].str.replace('Assoc-acdm', 'CommunityCollege')\n",
    "        df['education'] = df['education'].str.replace('Assoc-voc', 'CommunityCollege')\n",
    "        \n",
    "        # [' Never-married', ' Married-civ-spouse', ' Divorced',' Married-spouse-absent', ' Separated', ' Married-AF-spouse',\n",
    "        # ' Widowed']\n",
    "        df['marital-status'] = df['marital-status'].str.replace('Never-married','notMarried')\n",
    "        df['marital-status'] = df['marital-status'].str.replace('Seperated','notMarried')\n",
    "        df['marital-status'] = df['marital-status'].str.replace('Divorced','Seperated')\n",
    "        df['marital-status'] = df['marital-status'].str.replace('Seperated','Seperated')\n",
    "        df['marital-status'] = df['marital-status'].str.replace('Married-AF-spouse','Married')\n",
    "        df['marital-status'] = df['marital-status'].str.replace('Married-civ-spouse','Married')\n",
    "        df['marital-status'] = df['marital-status'].str.replace('Married-spouse-absent','Married')\n",
    "        \n",
    "        # Binning\n",
    "        \n",
    "        df.loc[df['education-num']  < 9,'education-num']   = 0 # dropout\n",
    "        df.loc[df['education-num'] == 9,'education-num']  = 1 # high school\n",
    "        df.loc[df['education-num'] == 10,'education-num'] = 2 # Community College\n",
    "        df.loc[df['education-num'] == 11,'education-num'] = 2 # Community College\n",
    "        df.loc[df['education-num'] == 12,'education-num'] = 2 # Community College\n",
    "        df.loc[df['education-num'] == 13,'education-num'] = 3 # Bachelor\n",
    "        df.loc[df['education-num'] == 14,'education-num'] = 4 # Master\n",
    "        df.loc[df['education-num'] == 15,'education-num'] = 5 # Prof-school\n",
    "        df.loc[df['education-num'] == 16,'education-num'] = 6 # Doctorate\n",
    "        \n",
    "        # binary\n",
    "        df.loc[df['capital-gain'] >= 2000,'capital-gain'] = 1\n",
    "        df.loc[df['capital-gain']  < 2000,'capital-gain'] = 0\n",
    "        \n",
    "        df.loc[df['capital-loss']  <= 600,'capital-loss'] = 1\n",
    "        df.loc[df['capital-loss']  > 600, 'capital-loss'] = 0\n",
    "        \n",
    "        return df\n",
    "    def take_model(self,model):\n",
    "        '''\n",
    "        Takes in model.\n",
    "        '''\n",
    "        self.model = model\n",
    "    def split_data(self,df):\n",
    "        \n",
    "        self.x_train,self.x_test, self.y_train, self.y_test = model_selection.train_test_split(df[self.columns_name],df['income'],test_size=0.2,random_state=2)\n",
    "\n",
    "        \n",
    "    def plain_training(self,train_df,test_df,selected):\n",
    "        '''\n",
    "        It trains model once and returns accuracy score\n",
    "        '''\n",
    "        self.x_train,self.x_test, self.y_train, self.y_test = model_selection.train_test_split(train_df[selected],train_df['income'],test_size=0.2,random_state=2)\n",
    "        self.x_train = self.normalize_data(self.x_train)\n",
    "        self.x_test = self.normalize_data(self.x_test)\n",
    "        test = self.normalize_data(test_df[selected])\n",
    "        clf = self.model()\n",
    "        clf.fit(self.x_train,self.y_train)\n",
    "        y_pred = clf.predict(test)\n",
    "        \n",
    "        return clf.score(self.x_test,self.y_test)\n",
    "    def generate_submission(self, y_pred):\n",
    "        '''\n",
    "        Saves submission in the right format.\n",
    "        '''\n",
    "        pred_df = pd.DataFrame()\n",
    "        pred_df['Id'] = np.arange(0,len(test_df[self.columns_name]))\n",
    "        pred_df['Category'] = y_pred\n",
    "        pred_df.to_csv('submission.csv',index=False)\n",
    "        \n",
    "    def encode_df(self,df):\n",
    "        '''\n",
    "        Encode string values in dataframe into numbers.\n",
    "        '''\n",
    "        \n",
    "        return df.apply(LabelEncoder().fit_transform)\n",
    "    def normalize_data(self, X):\n",
    "        # TO DO: Normalize the feature values of dataset X using the mean and standard deviation of the respective features \n",
    "    \n",
    "        return preprocessing.scale(X)\n",
    "    def one_hotencoder(self,df):\n",
    "        ''' Input data should be in number (encoded)'''\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        onehotencoder = OneHotEncoder()\n",
    "        data = onehotencoder.fit_transform(df).toarray()\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def kbins(self,df,bins):\n",
    "        from sklearn.preprocessing import KBinsDiscretizer\n",
    "        est = KBinsDiscretizer(n_bins=bins,encode='onehot-dense',strategy='kmeans')\n",
    "        est.fit(df)\n",
    "        Xt = est.transform(df)\n",
    "        return Xt\n",
    "    def kfold_cw(self,model,train_df,test_df,niter):\n",
    "        from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "        score = cross_val_score(model,train_df,test_df,cv=niter)\n",
    "        pred  = cross_val_predict(model,train_df,test_df,cv=niter)\n",
    "        return model,np.mean(score),pred\n",
    "    def randomforest_cw(self,train_df,test_df):\n",
    "        '''\n",
    "        Cross-validation training for Random Forest method.\n",
    "        '''\n",
    "        from sklearn.model_selection import KFold\n",
    "        \n",
    "        kfold = KFold(n_splits=5)\n",
    "        n_estimators = [int(x) for x in np.linspace(200,2000,10)]\n",
    "        for i in n_estimators:\n",
    "            # resample train and test data. Normalize test data in this step as well.\n",
    "            self.x_train,self.x_test, self.y_train, self.y_test = model_selection.train_test_split(train_df[self.columns_name],train_df['income'],test_size=0.2,random_state=2)\n",
    "            self.x_train = self.normalize_data(self.x_train)\n",
    "            self.x_test = self.normalize_data(self.x_test)\n",
    "            \n",
    "            # k-fold split again\n",
    "            \n",
    "            # train and fit on random forest method\n",
    "            randomforest = ensemble.RandomForestClassifier(max_depth=20, random_state=0)\n",
    "            randomforest.fit(self.x_train,self.y_train)\n",
    "            \n",
    "            # store n_estimator and it's accuracy value\n",
    "            \n",
    "        \n",
    "        test = self.normalize_data(test_df[selected])\n",
    "        \n",
    "        y_pred = randomforest.predict(test)\n",
    "        return y_pred, randomforest.score(self.x_test,self.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classification()\n",
    "df = clf.train_data\n",
    "# df = clf.preprocess(df)\n",
    "\n",
    "test_df = clf.test_data\n",
    "test_df = clf.preprocess(test_df)\n",
    "\n",
    "encoded_df = clf.encode_df(df)\n",
    "encoded_test_df = clf.encode_df(test_df)\n",
    "\n",
    "# kbins = clf.kbins(encoded_df,5)\n",
    "test_columns = ['age','workclass','fnlwgt','education-num','marital-status',\n",
    "               'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "               'hours-per-week']\n",
    "# encoded_df.head()\n",
    "# clf.take_model(ensemble.RandomForestClassifier)\n",
    "# clf.model\n",
    "# clf.plain_training(encoded_df,encoded_test_df,test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2491</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>2727</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>13188</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>14354</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18120</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>16567</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>7982</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>12746</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1225</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>7908</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0   22          5    2491          9             12               4   \n",
       "1   33          4    2727          9             12               2   \n",
       "2   21          2   13188         11              8               0   \n",
       "3   36          2   14354          1              6               2   \n",
       "4   11          2   18120          9             12               2   \n",
       "5   20          2   16567         12             13               2   \n",
       "6   32          2    7982          6              4               3   \n",
       "7   35          4   12746         11              8               2   \n",
       "8   14          2    1225         12             13               4   \n",
       "9   25          2    7908          9             12               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           0             1     4    1            24             0   \n",
       "1           3             0     4    1             0             0   \n",
       "2           5             1     4    1             0             0   \n",
       "3           5             0     2    1             0             0   \n",
       "4           9             5     2    0             0             0   \n",
       "5           3             5     4    0             0             0   \n",
       "6           7             1     2    0             0             0   \n",
       "7           3             0     4    1             0             0   \n",
       "8           9             1     4    0           104             0   \n",
       "9           3             0     4    1            78             0   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0              39              38       0  \n",
       "1              12              38       0  \n",
       "2              39              38       0  \n",
       "3              39              38       0  \n",
       "4              39               4       0  \n",
       "5              39              38       0  \n",
       "6              15              22       1  \n",
       "7              44              38       1  \n",
       "8              49              38       1  \n",
       "9              39              38       1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.4min\n"
     ]
    }
   ],
   "source": [
    "# Random forest parameter\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# now we instantiate the random search and fit it like any Sklearn model\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(encoded_df[:100][columns_name], encoded_df[:100]['income'])\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6033, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6033,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.split_data(encoded_df)\n",
    "print(clf.x_test.shape)\n",
    "clf.y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.3926 degrees.\n",
      "Accuracy = -inf%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy,predictions\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "test_features = clf.x_test\n",
    "test_features = clf.encode_df(test_features)\n",
    "test_labels = clf.y_test\n",
    "# test_labels = clf.encode_df(test_labels)\n",
    "random_accuracy,pred = evaluate(best_random, test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15496905, 0.37962651, 0.30631676, ..., 0.36953456, 0.31191919,\n",
       "       0.29294345])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.svm import SVC\n",
    "# clf.take_model(SVC)\n",
    "# clf.plain_training(encoded_df,encoded_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00010095938492371559"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.take_model(linear_model.Lasso)\n",
    "clf.plain_training(encoded_df,encoded_test_df,test_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566716393170894"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "clf.take_model(naive_bayes.GaussianNB)\n",
    "clf.plain_training(encoded_df,encoded_test_df,test_columns)\n",
    "# NB = naive_bayes.GaussianNB()\n",
    "# NB.fit(x_train,y_train)\n",
    "# y_pred = NB.predict(x_test)\n",
    "# accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of \n",
    "randomforest = ensemble.RandomForestClassifier(max_depth=3, random_state=0)\n",
    "randomforest.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5701972484667661"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model = Perceptron(tol=1e-3,random_state=0,penalty='l2',max_iter=20)\n",
    "model.fit(clf.x_train,clf.y_train)\n",
    "model.score(clf.x_test,clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5701972484667661"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(clf.x_test,clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
