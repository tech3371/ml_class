{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1 - KNN\n",
    "## CSCI 5622 - Spring 2020\n",
    "\n",
    "For today's assignment, we will be implementing our own K-Nearest Neighbors (KNN) algorithm.\n",
    "\n",
    "*But Professor Quigley, hasn't someone else already written KNN before?*\n",
    "\n",
    "Yes, you are not the first to implement KNN, or basically any algorithm we'll work with in this class. But 1) I'll know that you know what's really going on, and 2) you'll know you can do it, because 2a) someday you might have to implement some machine learning algorithm from scratch - maybe for a new platform (do you need to run python on your SmartToaster just to get it to learn how users like their toast?), maybe because you want to tweak the algorithm (there's always a better approach...), or maybe because you're working on something important and you need to control exactly what's on there (should you really be running anaconda on your secret spy plane?).\n",
    "\n",
    "That said - we're not going to implement *everything*. We'll start by importing a few helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wait a minute - didn't we just import Scikit-learn (sklearn)? The package with baked-in machine learning tools?*\n",
    "\n",
    "Yes - but it also has a ton of helper functions, including a dataset we'll be using later. But, for now, let's set up a KNNClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors\n",
    "\n",
    "class KNNClassifier:\n",
    "    \n",
    "    def __init__(self, X, y, k = 5):\n",
    "        \"\"\"\n",
    "        Initialize our custom KNN classifier\n",
    "        PARAMETERS\n",
    "        X - our training data features\n",
    "        y - our training data answers\n",
    "        k - the number of nearest neighbors to consider for classification\n",
    "        \"\"\"\n",
    "        self._model = sklearn.neighbors.BallTree(X)\n",
    "        self._y = y\n",
    "        self._k = k\n",
    "        self._counts = self.getCounts()\n",
    "        \n",
    "    def getCounts(self):\n",
    "        \"\"\"\n",
    "        Creates a dictionary storing the counts of each answer class found in y\n",
    "        RETURNS\n",
    "        counts - a dictionary of counts of answer classes\n",
    "        \"\"\"\n",
    "        counts = dict({1:0,-1:0})\n",
    "        #BEGIN Workspace 1.1\n",
    "        #TODO: Modify and/or add to counts so that it returns a count of each answer class found in y\n",
    "        #END Workspace 1.1\n",
    "        unique, counts = np.unique(self._y, return_counts=True)\n",
    "        counts = dict(zip(unique, counts))\n",
    "        return(counts)\n",
    "    \n",
    "    def majority(self, indices):\n",
    "        \"\"\"\n",
    "        Given indices, report the majority label of those points.\n",
    "        For a tie, report the most common label in the data set.\n",
    "        PARAMETERS\n",
    "        indices - an np.array, where each element is an index of a neighbor\n",
    "        RETURNS\n",
    "        label - the majority label of our neighbors\n",
    "        \"\"\"\n",
    "        label = 0\n",
    "        #BEGIN Workspace 1.2\n",
    "        #TODO: Determine majority, assign it to label\n",
    "        #END Workspace 1.2\n",
    "        digit = [0,1,2,3,4,5,6,7,8,9,-1]\n",
    "        result = []\n",
    "        for i in indices[0]: # loops through k closest neighbor's indices and counts labels\n",
    "#             print(i)\n",
    "#             print(\"value at index\",digit[digit.index(self._y[0][i])])\n",
    "            result.append(digit[digit.index(self._y[0][i])])\n",
    "        \n",
    "        result_count = dict((i, result.count(i)) for i in digit)\n",
    "#         print(result_count)\n",
    "        label = max(result_count, key=result_count.get)\n",
    "        return(label)\n",
    "    \n",
    "    def classify(self, point):\n",
    "        \"\"\"\n",
    "        Given a new data point, classify it according to the training data X and our number of neighbors k \n",
    "        into the appropriate class in our training answers y\n",
    "        PARAMETERS\n",
    "        point - a feature vector of our test point\n",
    "        RETURNS\n",
    "        ans - our predicted classification\n",
    "        \"\"\"\n",
    "        ans = 0\n",
    "        #BEGIN Workspace 1.3\n",
    "        #TODO: perform classification of point here\n",
    "        #HINT: use the majority function created above\n",
    "        #HINT: use the euclidian distance discussed in lecture to find nearest neighbors\n",
    "        #END Workspace 1.3\n",
    "        #print(\"point \", point)\n",
    "        #print(\"k neighbors: \",self._k)\n",
    "        dist, ind = self._model.query([point], k=self._k)\n",
    "        print(\"Indice of nearest neighbor\", ind)\n",
    "        ans = self.majority(ind)\n",
    "        return(ans)\n",
    "    \n",
    "    def confusionMatrix(self, testX, testY):\n",
    "        \"\"\"\n",
    "        Generate a confusion matrix for the given test set\n",
    "        PARAMETERS\n",
    "        testX - an np.array of feature vectors of test points\n",
    "        testY - the corresponding correct classifications of our test set\n",
    "        RETURN\n",
    "        C - an N*N np.array of counts, where N is the number of classes in our classifier\n",
    "        \"\"\"\n",
    "        C = np.array([])\n",
    "        #BEGIN Workspace 1.4\n",
    "#         print(testX[0])\n",
    "#         predicted = []\n",
    "#         for i in range(len(testX):\n",
    "#             val = self.classify(testX[i])\n",
    "#             print(\"point \", testX[i])\n",
    "#             print(\"predicted label \", val)\n",
    "#             if(val == testY[i]): # predicted right\n",
    "                \n",
    "#             predicted.append(val)\n",
    "#         print(\"correct result \", testY)\n",
    "        #TODO: Run classification for the test set, compare to test answers, and add counts to matrix\n",
    "        #END Workspace 1.4\n",
    "        return(C)\n",
    "    \n",
    "    def accuracy(self, C):\n",
    "        \"\"\"\n",
    "        Generate an accuracy score for the classifier based on the confusion matrix\n",
    "        PARAMETERS\n",
    "        C - an np.array of counts\n",
    "        RETURN\n",
    "        score - an accuracy score\n",
    "        \"\"\"\n",
    "        score = np.sum(C.diagonal()) / C.sum()\n",
    "        return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation on confusion matrix for reference:\n",
    "https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*But professor, this code isn't complete!*\n",
    "\n",
    "### Problem 1: Complete our KNN Classifier - 40 Points (10 each)\n",
    "\n",
    "1.1 - Complete the getCounts function to return the count of each class found in the training set\n",
    "\n",
    "1.2 - Complete the majority function to determine the majority class of a series of neighbors\n",
    "\n",
    "1.3 - Complete the classify function to capture the predicted class of a new datapoint\n",
    "\n",
    " - HINT: Use the BallTree documentation to determine how to retrieve neighbors from the model (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree)\n",
    "\n",
    "1.4 - Complete the confusionMatrix function to reveal the results of classification\n",
    "\n",
    "You can take a look at the unit tests below to see how we create data to input into our classifier, what kinds of things we expect as output, etc. You should also consider expanding the test cases to make sure your classifier is working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([1, -1, -1, 1, -1, 1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice of nearest neighbor [[0 4 6 3 2]]\n",
      "Indice of nearest neighbor [[2 6 1 4 3]]\n",
      "Indice of nearest neighbor [[6 3 4 0 2]]\n",
      "Indice of nearest neighbor [[0]]\n",
      "Indice of nearest neighbor [[2]]\n",
      "Indice of nearest neighbor [[6]]\n",
      "Indice of nearest neighbor [[0 4 6]]\n",
      "Indice of nearest neighbor [[2 6 1]]\n",
      "Indice of nearest neighbor [[6 4 3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.014s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class KNNTester(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.x = np.array([[3,1],[2,8], [2,7], [5,2],[3,2],[8,2],[2,4]])\n",
    "        self.y = np.array([[1, -1, -1, 1, -1, 1, -1]])\n",
    "        self.knnfive = KNNClassifier(self.x, self.y)\n",
    "        self.knnthree = KNNClassifier(self.x, self.y, 3)\n",
    "        self.knnone = KNNClassifier(self.x, self.y, 1)\n",
    "        \n",
    "        self.testPoints = np.array([[2,1], [2,6], [4, 4]])\n",
    "        self.px = [[2,1],[2,3],[7,1],[2,6],[4,4]]\n",
    "        self.py = [[1,-1,1,-1,-1]]\n",
    "        \n",
    "    def plot(self):\n",
    "        x = [i[0] for i in self.x]\n",
    "        y = [i[1] for i in self.x]\n",
    "        plt.scatter(x,y)\n",
    "        plt.show()\n",
    "    def testCounter(self):\n",
    "        \"\"\"\n",
    "        Test getCounts function from knnclassifier\n",
    "        \"\"\"\n",
    "        self.assertEqual(self.knnfive._counts[1], 3)\n",
    "        self.assertEqual(self.knnfive._counts[-1], 4)\n",
    "        \n",
    "    def testKNNOne(self):\n",
    "        \"\"\"\n",
    "        Test if the classifier returns \"correct\" (expected) classifications for k = 1\n",
    "        \"\"\"\n",
    "        self.assertEqual(self.knnone.classify(self.testPoints[0]), 1)\n",
    "        self.assertEqual(self.knnone.classify(self.testPoints[1]), -1)\n",
    "        self.assertEqual(self.knnone.classify(self.testPoints[2]), -1)\n",
    "        \n",
    "    #BEGIN Workspace\n",
    "    #Add more test functions as desired\n",
    "    #HINT - You'll want to make sure each of your functions from the KNNClassifier class you created work correctly...\n",
    "    #END Workspace \n",
    "    def testKNNThree(self):\n",
    "        '''\n",
    "        Test if the classifier returns \"correct\" classification for k=3\n",
    "        '''\n",
    "        self.assertEqual(self.knnthree.classify(self.testPoints[0]),-1)\n",
    "        self.assertEqual(self.knnthree.classify(self.testPoints[1]),-1)\n",
    "        self.assertEqual(self.knnthree.classify(self.testPoints[2]),-1)\n",
    "        \n",
    "    def testKNNFive(self):\n",
    "        '''\n",
    "        Test if the classifier returns \"correct\" classification for k=3\n",
    "        '''\n",
    "        self.assertEqual(self.knnfive.classify(self.testPoints[0]),-1)\n",
    "        self.assertEqual(self.knnfive.classify(self.testPoints[1]),-1)\n",
    "        self.assertEqual(self.knnfive.classify(self.testPoints[2]),-1)\n",
    "    def testConfusionMatrix(self):\n",
    "        self.knnone.confusionMatrix(self.px,self.py)\n",
    "    \n",
    "tests = KNNTester()\n",
    "tests.setUp()\n",
    "# tests.plot()\n",
    "myTests = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(myTests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - now we've demonstrated that our KNN classifier works, let's think about our problem space! \n",
    "\n",
    "## Our Dataset - Identifying Digits from Images\n",
    "\n",
    "It's a pretty common problem - just imagine working at the post office, or at a bank, and you're handed a hand-written envelope, or check, or other piece of information and you have to identify exactly what it says. Did they pay 500 or 600 dollars? Is the letter going to 80309 (campus) or 30309 (Atlanta)?\n",
    "\n",
    "Let's be a little smart about this - let's up some classes and helper functions to help us out.\n",
    "\n",
    "### Problem 2: Implement KNN on Digits dataset - 30 Points\n",
    "\n",
    "2.1 Randomly divide our Digits dataset into training and testing sets (15 Points)\n",
    "\n",
    "2.2 Report the number of examples in training and testing, as well as measuring then number of pixels in each image (5 points)\n",
    "\n",
    "2.3 Create a confusion matrix of our classifier for K = 5 (10 points) *HINT: Doing this may cause you to catch mistakes in your classifier. Go fix those!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Are we running training on 'data' or 'images' datasets?\n",
    "# # from sklearn.model_selection import train_test_split. Can we use that to split data? \n",
    "# # https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "# # Can we use pandas to store data in dataframe.\n",
    "# digits = sklearn.datasets.load_digits()\n",
    "# # df = pd.DataFrame()\n",
    "# # df['data'] = [digits['data'][i] for i in range(len(digits['data']))]\n",
    "# plt.gray() \n",
    "# plt.matshow(digits.images[44]) \n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = range(0,len(digits['data']))\n",
    "# train_size = int(len(digits['data']) * 0.8)\n",
    "# test_size = int(len(digits['data']) * 0.2)\n",
    "# print(n)\n",
    "# train_indices = sample(arr,train_size)\n",
    "# test_indices = sample(arr,test_size)\n",
    "# xtrain = [digits['data'][i] for i in train_indices]\n",
    "# xtrain = [x.tolist() for x in xtrain]\n",
    "# ytrain = [digits['target'][i] for i in train_indices]\n",
    "# xtest = [digits['data'][i] for i in test_indices]\n",
    "# ytest = [digits['target'][i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Numbers:\n",
    "    def __init__(self):\n",
    "        #load data from sklearn\n",
    "        digits = sklearn.datasets.load_digits()        \n",
    "        #BEGIN Workspace 2.1\n",
    "        # features ==> digits['data']\n",
    "        # class ==> digits['target_names']\n",
    "        # features_map_to ==> digits['target']\n",
    "        \n",
    "        arr        = range(0,len(digits['data']))\n",
    "        train_size = int(len(digits['data']) * 0.8)\n",
    "        test_size  = int(len(digits['data']) * 0.2)\n",
    "        \n",
    "        train_indices = sample(arr,train_size)\n",
    "        test_indices  = sample(arr,test_size)\n",
    "        \n",
    "        xtrain  = [digits['data'][i] for i in train_indices]\n",
    "        xtrain  = [x.tolist() for x in xtrain]\n",
    "        ytrain  = [digits['target'][i] for i in train_indices]\n",
    "        ytrain  = [x.tolist() for x in ytrain]\n",
    "        \n",
    "        xtest   = [digits['data'][i] for i in test_indices]\n",
    "        ytest   = [digits['target'][i] for i in test_indices]\n",
    "        xtest   = [x.tolist() for x in xtest]\n",
    "        ytest   = [x.tolist() for x in ytest]\n",
    "        \n",
    "        self.train_x = np.array(xtrain) # A 2D np.array of training examples, REPLACE\n",
    "        self.train_y = np.array(ytrain) # A 1D np.array of training answers, REPLACE\n",
    "        self.test_x = np.array(xtest) # A 2D np.array of testing examples, REPLACE\n",
    "        self.test_y = np.array(ytest) # A 1D np.array of testing answers, REPLACE\n",
    "        #TODO: Divide our dataset into Train and Test datasets (80/20 split), replacing the variables above\n",
    "        #END Workspace 2.1\n",
    "        \n",
    "    def report(self):\n",
    "        \"\"\"\n",
    "        Report information about the dataset using the print() function\n",
    "        \"\"\"\n",
    "        #BEGIN Workspace 2.2\n",
    "        #TODO: Create printouts for reporting the size of each set and the size of each datapoint\n",
    "        #END Workspace 2.2\n",
    "#         shape =  digit['images'].shape\n",
    "#         print(\"The shape of Images data is {} X {} squares repeated in {} rows \".format(shape[1],shape[2],shape[0]))\n",
    "\n",
    "    def classify(self):\n",
    "        \"\"\"\n",
    "        Create a classifier using the training data and generate a confusion matrix for the test data\n",
    "        \"\"\"\n",
    "        #BEGIN Workspace 2.3\n",
    "        #TODO: Create classifier from training data, generate confusion matrix for test data\n",
    "        #END Workspace 2.3\n",
    "        digit = KNNClassifier(self.train_x, self.train_y)\n",
    "        print(self.train_x[0])\n",
    "        print(digit.getCounts())\n",
    "        digit.classify(self.train_x[0])\n",
    "    def viewDigit(self, digitImage):\n",
    "        \"\"\"\n",
    "        Display an image of a digit\n",
    "        PARAMETERS\n",
    "        digitImage - a data object from the dataset\n",
    "        \"\"\"\n",
    "        plt.gray()\n",
    "        plt.matshow(digitImage)\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  6. 16.  8.  0.  0.  0.  0.  0.  8. 13. 16.  3.  0.  0.  0.  0.\n",
      "  2. 12. 10.  8.  0.  0.  0.  0.  0.  0.  7. 11.  0.  0.  0.  0.  0.  0.\n",
      "  9. 10.  0.  0.  0.  0.  0.  0. 13.  7.  0.  0.  0.  0.  1. 10. 16. 10.\n",
      "  8.  3.  0.  0.  4. 16. 16. 15. 16. 16.]\n",
      "{0: 142, 1: 146, 2: 155, 3: 145, 4: 153, 5: 140, 6: 133, 7: 142, 8: 138, 9: 143}\n",
      "Indice of nearest neighbor [[   0  996 1210 1311   44]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-1072ae669d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(test.train_x[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# test.viewDigit(digits['images'][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-bed05467e52f>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mdigit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mviewDigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigitImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n",
      "\u001b[0;32m<ipython-input-55-7cb78f11f327>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, point)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Indice of nearest neighbor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajority\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-7cb78f11f327>\u001b[0m in \u001b[0;36mmajority\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#             print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#             print(\"value at index\",digit[digit.index(self._y[0][i])])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdigit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresult_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdigit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "test = Numbers()\n",
    "test.report()\n",
    "test.classify()\n",
    "# print(test.train_x[0])\n",
    "# test.viewDigit(digits['images'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wow, I can't believe we just created a KNN Classifier - but can't we make it better?*\n",
    "\n",
    "Yes, we saw above that our classifier didn't work perfectly. Let's explore that issue a little further\n",
    "\n",
    "### Problem 3: Improving KNN on Digits - 30 Points\n",
    "\n",
    "3.1 Determine which classes are most often confused (from our confusion matrix above), inspect some examples of these digits (using the viewDigit function in our Numbers class), and write a brief (4 - 5 sentences) description of why you think these particular numbers may be misclassified.\n",
    "\n",
    "3.2 Explore the influence of the number of nearest neighbors (i.e. try changing our K). Plot the relationship between K and accuracy, and write a brief (4 - 5 sentences) description of how this factor impacts our accuracy.\n",
    "\n",
    "3.3 (Bonus) Explore the influence of the train / test split of our data (i.e. copy our Numbers class into Numbers2 below and try changing the split for our dataset). Plot the relationship between the split % and accuracy, and write a brief (4 - 5 sentences) description of its impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN 3.1a\n",
    "#TODO: Print out problem class images\n",
    "#END 3.1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1b\n",
    "TODO: Write description of misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Numbers2:\n",
    "    def __init__(self, trainPercentage):\n",
    "        #load data from sklearn\n",
    "        digits = sklearn.datasets.load_digits()\n",
    "        \n",
    "        #BEGIN Workspace 3.3a\n",
    "        self.train_x = np.array() # A 2D np.array of training examples, REPLACE\n",
    "        self.train_y = np.array() # A 1D np.array of training answers, REPLACE\n",
    "        self.test_x = np.array() # A 2D np.array of testing examples, REPLACE\n",
    "        self.test_y = np.array() # A 1D np.array of testing answers, REPLACE\n",
    "        #TODO: Divide our dataset into Train and Test datasets (using trainPercentage), replacing the variables above\n",
    "        #HINT: You should be able to mostly copy your own work from the original Numbers class\n",
    "        #END Workspace 3.3a\n",
    "\n",
    "    def classify(self, k):\n",
    "        \"\"\"\n",
    "        Create a classifier using the training data and generate a confusion matrix for the test data\n",
    "        \"\"\"\n",
    "        #BEGIN Workspace 3.2a\n",
    "        #TODO: Create classifier from training data (using k nearest neighbors), generate confusion matrix for test data\n",
    "        #HINT: You can copy your own work from the original Numbers class\n",
    "        #END Workspace 3.2a\n",
    "        \n",
    "    def viewDigit(digitImage):\n",
    "        \"\"\"\n",
    "        Display an image of a digit\n",
    "        PARAMETERS\n",
    "        digitImage - a data object from the dataset\n",
    "        \"\"\"\n",
    "        plt.gray()\n",
    "        plt.matshow(digitImage)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2b\n",
    "TODO: Write description of influence of neighbor count\n",
    "\n",
    "#### 3.3b\n",
    "TODO: Write description of influence of training / testing split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
