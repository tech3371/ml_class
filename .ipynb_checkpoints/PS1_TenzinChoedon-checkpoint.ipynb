{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1 - KNN\n",
    "## CSCI 5622 - Spring 2020\n",
    "\n",
    "For today's assignment, we will be implementing our own K-Nearest Neighbors (KNN) algorithm.\n",
    "\n",
    "*But Professor Quigley, hasn't someone else already written KNN before?*\n",
    "\n",
    "Yes, you are not the first to implement KNN, or basically any algorithm we'll work with in this class. But 1) I'll know that you know what's really going on, and 2) you'll know you can do it, because 2a) someday you might have to implement some machine learning algorithm from scratch - maybe for a new platform (do you need to run python on your SmartToaster just to get it to learn how users like their toast?), maybe because you want to tweak the algorithm (there's always a better approach...), or maybe because you're working on something important and you need to control exactly what's on there (should you really be running anaconda on your secret spy plane?).\n",
    "\n",
    "That said - we're not going to implement *everything*. We'll start by importing a few helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wait a minute - didn't we just import Scikit-learn (sklearn)? The package with baked-in machine learning tools?*\n",
    "\n",
    "Yes - but it also has a ton of helper functions, including a dataset we'll be using later. But, for now, let's set up a KNNClassifier class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation on confusion matrix for reference:\n",
    "https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors\n",
    "\n",
    "class KNNClassifier:\n",
    "    \n",
    "    def __init__(self, X, y, k = 5):\n",
    "        \"\"\"\n",
    "        Initialize our custom KNN classifier\n",
    "        PARAMETERS\n",
    "        X - our training data features\n",
    "        y - our training data answers\n",
    "        k - the number of nearest neighbors to consider for classification\n",
    "        \"\"\"\n",
    "        self._model = sklearn.neighbors.BallTree(X)\n",
    "        self._y = y\n",
    "        self._k = k\n",
    "        self._counts = self.getCounts()\n",
    "        \n",
    "    def getCounts(self):\n",
    "        \"\"\"\n",
    "        Creates a dictionary storing the counts of each answer class found in y\n",
    "        RETURNS\n",
    "        counts - a dictionary of counts of answer classes\n",
    "        \"\"\"\n",
    "        counts = dict({1:0,-1:0})\n",
    "        #BEGIN Workspace 1.1\n",
    "        #TODO: Modify and/or add to counts so that it returns a count of each answer class found in y\n",
    "        #END Workspace 1.1\n",
    "        unique, counts = np.unique(self._y, return_counts=True)\n",
    "        counts = dict(zip(unique, counts))\n",
    "        return(counts)\n",
    "    \n",
    "    def majority(self, indices):\n",
    "        \"\"\"\n",
    "        Given indices, report the majority label of those points.\n",
    "        For a tie, report the most common label in the data set.\n",
    "        PARAMETERS\n",
    "        indices - an np.array, where each element is an index of a neighbor\n",
    "        RETURNS\n",
    "        label - the majority label of our neighbors\n",
    "        \"\"\"\n",
    "        label = 0\n",
    "        #BEGIN Workspace 1.2\n",
    "        #TODO: Determine majority, assign it to label\n",
    "        #END Workspace 1.2\n",
    "        digit = [0,1,2,3,4,5,6,7,8,9,-1]\n",
    "        result = []\n",
    "        for i in indices[0]: # loops through k closest neighbor's indices and get which digit it is and stores it.\n",
    "            result.append(digit[digit.index(self._y[0][i])])\n",
    "        \n",
    "        result_count = dict((i, result.count(i)) for i in digit) # loop through all nearest digits and gets its' count.\n",
    "        desc_ind_list = sorted(result_count, key=result_count.get, reverse=True) # sortes result_count into descending order\n",
    "        \n",
    "        if(result_count[desc_ind_list[0]] == result_count[desc_ind_list[1]]): # equal weigth\n",
    "            #print(\"Tie between {} : {} !\".format(desc_ind_list[0],desc_ind_list[1]))\n",
    "            count = self.getCounts() # gets counts of each digits\n",
    "            \n",
    "            # give label to the max value in the count.\n",
    "            if(count[desc_ind_list[0]] > count[desc_ind_list[1]]): label = desc_ind_list[0]\n",
    "            else: label = desc_ind_list[1]\n",
    "                \n",
    "            #print(\"label assigned after tie: \",label)\n",
    "            \n",
    "        else:\n",
    "            label = desc_ind_list[0]  \n",
    "            \n",
    "        return(label)\n",
    "    \n",
    "    def classify(self, point):\n",
    "        \"\"\"\n",
    "        Given a new data point, classify it according to the training data X and our number of neighbors k \n",
    "        into the appropriate class in our training answers y\n",
    "        PARAMETERS\n",
    "        point - a feature vector of our test point\n",
    "        RETURNS\n",
    "        ans - our predicted classification\n",
    "        \"\"\"\n",
    "        ans = 0\n",
    "        #BEGIN Workspace 1.3\n",
    "        #TODO: perform classification of point here\n",
    "        #HINT: use the majority function created above\n",
    "        #HINT: use the euclidian distance discussed in lecture to find nearest neighbors\n",
    "        #END Workspace 1.3\n",
    "        dist, ind = self._model.query([point], k=self._k) # returns distance and indices of k nearest neighbors\n",
    "        ans = self.majority(ind)\n",
    "        return(ans)\n",
    "    \n",
    "    def confusionMatrix(self, testX, testY):\n",
    "        \"\"\"\n",
    "        Generate a confusion matrix for the given test set\n",
    "        PARAMETERS\n",
    "        testX - an np.array of feature vectors of test points\n",
    "        testY - the corresponding correct classifications of our test set\n",
    "        RETURN\n",
    "        C - an N*N np.array of counts, where N is the number of classes in our classifier\n",
    "        \"\"\"\n",
    "        # get unique values in self.y to determine N\n",
    "        N = len(set(self._y[0]))\n",
    "        C = np.array(np.zeros([N,N]))\n",
    "        key_map = {-1:0,0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9} # Using mapping to index in matrix\n",
    "\n",
    "        #BEGIN Workspace 1.4\n",
    "        #TODO: Run classification for the test set, compare to test answers, and add counts to matrix\n",
    "        for i in range(len(testX)):\n",
    "            C[key_map[testX[i]]][key_map[testY[i]]] += 1\n",
    "        #END Workspace 1.4\n",
    "        \n",
    "        return(C)\n",
    "    \n",
    "    def accuracy(self, C):\n",
    "        \"\"\"\n",
    "        Generate an accuracy score for the classifier based on the confusion matrix\n",
    "        PARAMETERS\n",
    "        C - an np.array of counts\n",
    "        RETURN\n",
    "        score - an accuracy score\n",
    "        \"\"\"\n",
    "        score = np.sum(C.diagonal()) / C.sum()\n",
    "        return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*But professor, this code isn't complete!*\n",
    "\n",
    "### Problem 1: Complete our KNN Classifier - 40 Points (10 each)\n",
    "\n",
    "1.1 - Complete the getCounts function to return the count of each class found in the training set\n",
    "\n",
    "1.2 - Complete the majority function to determine the majority class of a series of neighbors\n",
    "\n",
    "1.3 - Complete the classify function to capture the predicted class of a new datapoint\n",
    "\n",
    " - HINT: Use the BallTree documentation to determine how to retrieve neighbors from the model (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree)\n",
    "\n",
    "1.4 - Complete the confusionMatrix function to reveal the results of classification\n",
    "\n",
    "You can take a look at the unit tests below to see how we create data to input into our classifier, what kinds of things we expect as output, etc. You should also consider expanding the test cases to make sure your classifier is working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[3. 0.]\n",
      " [0. 2.]]\n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.018s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=6 errors=0 failures=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class KNNTester(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.x = np.array([[3,1],[2,8], [2,7], [5,2],[3,2],[8,2],[2,4]])\n",
    "        self.y = np.array([[1, -1, -1, 1, -1, 1, -1]])\n",
    "        self.knnfive = KNNClassifier(self.x, self.y)\n",
    "        self.knnthree = KNNClassifier(self.x, self.y, 3)\n",
    "        self.knnone = KNNClassifier(self.x, self.y, 1)\n",
    "        \n",
    "        \n",
    "        self.testPoints = np.array([[2,1], [2,6], [4, 4]])\n",
    "        self.test = np.array([[2,1],[2,3],[7,1],[2,6],[4,4]])\n",
    "        self.px = [1,-1,1,-1,-1]\n",
    "        self.knntwo = KNNClassifier(self.test,[self.px],2)\n",
    "        self.py = []\n",
    "        for i in self.test:\n",
    "            self.py.append(self.knnone.classify(i))\n",
    "    def plot(self):\n",
    "        x = [i[0] for i in self.x]\n",
    "        y = [i[1] for i in self.x]\n",
    "        plt.scatter(x,y)\n",
    "        plt.show()\n",
    "    def testCounter(self):\n",
    "        \"\"\"\n",
    "        Test getCounts function from knnclassifier\n",
    "        \"\"\"\n",
    "        self.assertEqual(self.knnfive._counts[1], 3)\n",
    "        self.assertEqual(self.knnfive._counts[-1], 4)\n",
    "        \n",
    "    def testKNNOne(self):\n",
    "        \"\"\"\n",
    "        Test if the classifier returns \"correct\" (expected) classifications for k = 1\n",
    "        \"\"\"\n",
    "        self.assertEqual(self.knnone.classify(self.testPoints[0]), 1)\n",
    "        self.assertEqual(self.knnone.classify(self.testPoints[1]), -1)\n",
    "        self.assertEqual(self.knnone.classify(self.testPoints[2]), -1)\n",
    "        \n",
    "    #BEGIN Workspace\n",
    "    #Add more test functions as desired\n",
    "    #HINT - You'll want to make sure each of your functions from the KNNClassifier class you created work correctly...\n",
    "    #END Workspace \n",
    "    \n",
    "    def testKNNTwo(self):\n",
    "        self.assertEqual(self.knntwo.classify(self.testPoints[0]),-1)\n",
    "    def testKNNThree(self):\n",
    "        '''\n",
    "        Test if the classifier returns \"correct\" classification for k=3\n",
    "        '''\n",
    "        self.assertEqual(self.knnthree.classify(self.testPoints[0]),-1)\n",
    "        self.assertEqual(self.knnthree.classify(self.testPoints[1]),-1)\n",
    "        self.assertEqual(self.knnthree.classify(self.testPoints[2]),-1)\n",
    "        \n",
    "    def testKNNFive(self):\n",
    "        '''\n",
    "        Test if the classifier returns \"correct\" classification for k=3\n",
    "        '''\n",
    "        self.assertEqual(self.knnfive.classify(self.testPoints[0]),-1)\n",
    "        self.assertEqual(self.knnfive.classify(self.testPoints[1]),-1)\n",
    "        self.assertEqual(self.knnfive.classify(self.testPoints[2]),-1)\n",
    "    def testConfusionMatrix(self):\n",
    "        print(\"Confusion Matrix: \\n\", self.knnone.confusionMatrix(self.px,self.py))\n",
    "        print(\"Accuracy: \\n\", self.knnone.accuracy(self.knnone.confusionMatrix(self.px,self.py)))\n",
    "    \n",
    "tests = KNNTester()\n",
    "tests.setUp()\n",
    "myTests = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(myTests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - now we've demonstrated that our KNN classifier works, let's think about our problem space! \n",
    "\n",
    "## Our Dataset - Identifying Digits from Images\n",
    "\n",
    "It's a pretty common problem - just imagine working at the post office, or at a bank, and you're handed a hand-written envelope, or check, or other piece of information and you have to identify exactly what it says. Did they pay 500 or 600 dollars? Is the letter going to 80309 (campus) or 30309 (Atlanta)?\n",
    "\n",
    "Let's be a little smart about this - let's up some classes and helper functions to help us out.\n",
    "\n",
    "### Problem 2: Implement KNN on Digits dataset - 30 Points\n",
    "\n",
    "2.1 Randomly divide our Digits dataset into training and testing sets (15 Points)\n",
    "\n",
    "2.2 Report the number of examples in training and testing, as well as measuring then number of pixels in each image (5 points)\n",
    "\n",
    "2.3 Create a confusion matrix of our classifier for K = 5 (10 points) *HINT: Doing this may cause you to catch mistakes in your classifier. Go fix those!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Numbers:\n",
    "    def __init__(self):\n",
    "        #load data from sklearn\n",
    "        digits = sklearn.datasets.load_digits()        \n",
    "        #BEGIN Workspace 2.1\n",
    "        # features ==> digits['data']\n",
    "        # class ==> digits['target_names']\n",
    "        # features_map_to ==> digits['target']\n",
    "        #TODO: Divide our dataset into Train and Test datasets (80/20 split), replacing the variables above\n",
    "        #END Workspace 2.1\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(digits['data'], digits['target'], test_size=0.20, random_state=42)\n",
    "\n",
    "        \n",
    "    def report(self):\n",
    "        \"\"\"\n",
    "        Report information about the dataset using the print() function\n",
    "        \"\"\"\n",
    "        #BEGIN Workspace 2.2\n",
    "        #TODO: Create printouts for reporting the size of each set and the size of each datapoint\n",
    "        #END Workspace 2.2\n",
    "        digits = sklearn.datasets.load_digits()\n",
    "        print(\"Total data: \", digits['data'].shape)\n",
    "        print(\"\")\n",
    "        print(\"Train Data:\\n{} rows and {} datapoints \".format(self.train_x.shape[0],self.train_x.shape[1]))\n",
    "        print(\"Train Label:\\n{} rows \".format(self.train_y.shape[0]))\n",
    "        print(\"\")\n",
    "        print(\"Test Data:\\n{} rows and {} datapoints \".format(self.test_x.shape[0],self.test_x.shape[1]))\n",
    "        print(\"Test Label:\\n{} rows \".format(self.test_y.shape[0]))\n",
    "        print(\"\")\n",
    "        print(\"Each images is {} x {} pixels resolution\".format(digits['images'].shape[1],digits['images'].shape[2]))\n",
    "        print(\"\")\n",
    "        \n",
    "    def classify(self):\n",
    "        \"\"\"\n",
    "        Create a classifier using the training data and generate a confusion matrix for the test data\n",
    "        \"\"\"\n",
    "        #BEGIN Workspace 2.3\n",
    "        #TODO: Create classifier from training data, generate confusion matrix for test data\n",
    "        #END Workspace 2.3\n",
    "        predicted_value = []\n",
    "        digit_knn = KNNClassifier(self.train_x, [self.train_y],5)\n",
    "        for i in self.test_x:\n",
    "            predicted_value.append(digit_knn.classify(i))\n",
    "            \n",
    "        print(\"Confusion Matrix: \\n\\n\",digit_knn.confusionMatrix(self.test_y,predicted_value))\n",
    "        print(\"\\nAccuracy: \\n\", digit_knn.accuracy(digit_knn.confusionMatrix(self.test_y,predicted_value)))\n",
    "    def viewDigit(self, digitImage):\n",
    "        \"\"\"\n",
    "        Display an image of a digit\n",
    "        PARAMETERS\n",
    "        digitImage - a data object from the dataset\n",
    "        \"\"\"\n",
    "        plt.gray()\n",
    "        plt.matshow(digitImage)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data:  (1797, 64)\n",
      "\n",
      "Train Data:\n",
      "1437 rows and 64 datapoints \n",
      "Train Label:\n",
      "1437 rows \n",
      "\n",
      "Test Data:\n",
      "360 rows and 64 datapoints \n",
      "Test Label:\n",
      "360 rows \n",
      "\n",
      "Each images is 8 x 8 pixels resolution\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      " [[33.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 28.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 33.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 34.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 46.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 45.  1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0. 35.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 33.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 30.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  0.  0.  0. 38.]]\n",
      "\n",
      "Accuracy: \n",
      " 0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "test = Numbers()\n",
    "test.report()\n",
    "test.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wow, I can't believe we just created a KNN Classifier - but can't we make it better?*\n",
    "\n",
    "Yes, we saw above that our classifier didn't work perfectly. Let's explore that issue a little further\n",
    "\n",
    "### Problem 3: Improving KNN on Digits - 30 Points\n",
    "\n",
    "3.1 Determine which classes are most often confused (from our confusion matrix above), inspect some examples of these digits (using the viewDigit function in our Numbers class), and write a brief (4 - 5 sentences) description of why you think these particular numbers may be misclassified.\n",
    "\n",
    "3.2 Explore the influence of the number of nearest neighbors (i.e. try changing our K). Plot the relationship between K and accuracy, and write a brief (4 - 5 sentences) description of how this factor impacts our accuracy.\n",
    "\n",
    "3.3 (Bonus) Explore the influence of the train / test split of our data (i.e. copy our Numbers class into Numbers2 below and try changing the split for our dataset). Plot the relationship between the split % and accuracy, and write a brief (4 - 5 sentences) description of its impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN 3.1a\n",
    "#TODO: Print out problem class images\n",
    "digits = sklearn.datasets.load_digits()\n",
    "# prints digits image\n",
    "# for i in digits['target_names']:\n",
    "#     print(test.viewDigit(digits['images'][i]))\n",
    "#END 3.1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1b\n",
    "TODO: Write description of misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Numbers2:\n",
    "    def __init__(self, trainPercentage):\n",
    "        #load data from sklearn\n",
    "        digits = sklearn.datasets.load_digits()        \n",
    "        #BEGIN Workspace 2.1\n",
    "        # features ==> digits['data']\n",
    "        # class ==> digits['target_names']\n",
    "        # features_map_to ==> digits['target']\n",
    "        #TODO: Divide our dataset into Train and Test datasets (80/20 split), replacing the variables above\n",
    "        #END Workspace 2.1\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(digits['data'], digits['target'], test_size=(1-trainPercentage), random_state=42)\n",
    "\n",
    "    def classify(self):\n",
    "        \"\"\"\n",
    "        Create a classifier using the training data and generate a confusion matrix for the test data\n",
    "        \"\"\"\n",
    "        #BEGIN Workspace 2.3\n",
    "        #TODO: Create classifier from training data, generate confusion matrix for test data\n",
    "        #END Workspace 2.3\n",
    "        predicted_value = []\n",
    "        digit_knn = KNNClassifier(self.train_x, [self.train_y],5)\n",
    "        for i in self.test_x:\n",
    "            predicted_value.append(digit_knn.classify(i))\n",
    "        #print(predicted_value)\n",
    "        print(\"Confusion Matrix: \\n\",digit_knn.confusionMatrix(self.test_y,predicted_value))\n",
    "        print(\"Accuracy: \\n\", digit_knn.accuracy(digit_knn.confusionMatrix(self.test_y,predicted_value)))\n",
    "    def viewDigit(self, digitImage):\n",
    "        \"\"\"\n",
    "        Display an image of a digit\n",
    "        PARAMETERS\n",
    "        digitImage - a data object from the dataset\n",
    "        \"\"\"\n",
    "        plt.gray()\n",
    "        plt.matshow(digitImage)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 145,\n",
       " 1: 154,\n",
       " 2: 144,\n",
       " 3: 149,\n",
       " 4: 135,\n",
       " 5: 135,\n",
       " 6: 146,\n",
       " 7: 145,\n",
       " 8: 144,\n",
       " 9: 140}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit = KNNClassifier(test.train_x, [test.train_y])\n",
    "digit.getCounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "k_val = []\n",
    "acc = []\n",
    "for k in range(2,40):\n",
    "    k_val.append(k)\n",
    "    test = Numbers2(0.8)\n",
    "    predicted_value = []\n",
    "    digit_knn = KNNClassifier(test.train_x, [test.train_y],k)\n",
    "    for i in test.test_x:\n",
    "        predicted_value.append(digit_knn.classify(i))\n",
    "    acc.append(digit_knn.accuracy(digit_knn.confusionMatrix(test.test_y,predicted_value)))\n",
    "plt.scatter(k_val,acc)\n",
    "plt.xlabel(\"k value\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n",
    "#     #print(predicted_value)\n",
    "#     print(\"Confusion Matrix: \\n\",digit_knn.confusionMatrix(test.test_y,predicted_value))\n",
    "#     print(\"Accuracy: \\n\", digit_knn.accuracy(digit_knn.confusionMatrix(test.test_y,predicted_value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2b\n",
    "TODO: Write description of influence of neighbor count\n",
    "\n",
    "#### 3.3b\n",
    "TODO: Write description of influence of training / testing split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
